# 数据结构

## 绪论

### 时间复杂度
基本套路：设执行T次。

循环嵌套之间不是简单的乘法关系，请注意。

>如：
>内层每次执行n次，一共执行上层次数logn次：
>则一共n*logn = nlogn 次
>
>内层每次执行次数不一样
>但一共执行2^{上层次数}，而上层执行logn次，
>则一共2^logn = n次

我们期望找到总次数与各循环执行次数之间的关系。

```
x=2;
while(x<n/2)
x = x*2;

设执行了t次，
则跳出循环时2^t >= n/2
近似为2^t ~ n/2 n
取对数log2,左侧为t,右侧为log2(n/2)~log2(n)
则时间复杂度为log2(n)
```

```
较为复杂的类型：循环直接有纠缠
int sum=0;
for(int i=1;i<n;i*=2)
    for(int j=0;j<i;j++)
        sum++

不难看出内层循环次数取决的当前的i
而外层循环的次数为log(n)
计：外层循环执行了K次，,K~log(n)当前的i=2^K
总的次数，T，内层循环次数为：1+2+4+8+...+2^K
等比数列求和知T~2^K。而K~log(n) 则T~2^logn~n
所以时间复杂度为O(n)
```

## 线性表

### 单链表

```
typedef struct Node{
    int data;
    struct Node* next;
}Node;

#通常而言我们整一个头指针，专门用来链接一串Node
#给该指针分配内存:大小是Node，类型是Node*
Node * head = (Node*)malloc(sizeof(Node));
head->next = NULL;

#头插建立一串链表:
while(Condition){
    Node * new = (Node*)malloc(sizeof(Node));
    new->next=NULL;
    new->int = value;
    #插到头后面
    head->next = new;
}
#尾插法，那需要维持一个额外的尾指针
Node * rear = head;
while(Condition){
    Node * new = (Node*)malloc(sizeof(Node));
    new->next=NULL;
    new->int = value;
    rear->next =new;
    #更新尾指针
    rear = new;
}

#对链表的插入，通常是在后面插。而前插需要第二遍遍历到i-1个节点再后插。
#而有一个*奇淫技巧*可以使额外的开销仅为O(1)
#即在插入后交换这两个节点的data值
Node * insertNode = (Node*)malloc(sizeof(Node));
Node * insertPrt = head;
for(;i<pos;i++){
    insertPtr = insertPrt->next;
}
#插入
insertNode->next = insertPtr->next;
insertPtr->next = insertNode;
#交换完成前插
int temp = insertPtr->data;
insertPtr->data = insertNode->data;
insertNode ->data = temp;
```
### 循环链表

循环链表的最后一个节点指回头节点。
双循环链表头节点的前驱节点指回尾节点。

## 栈 队列 数组

### 栈

```
请注意数据结构里常见的栈顺序
与x86架构下内存中栈区的顺序相反
x86中栈由高地址向地地址增长。
```
此处只描述顺序栈。链栈不常见。
```
typedef struct{
    int data[size];
    int top;
}Stack;
#顺序栈所谓的栈顶指针，更像是一个“游标”，而不是指针。

#入栈
if(S.top==size-1)
    return -1;
S.data[++top] = value;
return 1;
#出栈
if(S.top==0)
    return -1;
S.top--;
return 1;
```

#### 栈与括号匹配

如：[({[]})]
左括号依次入栈。
遇到有括号，则对应出栈操作，但括号必须匹配。如]必须匹配[才允许出栈。
不然认为非法，括号顺序乱了。

#### 后缀表达式求值

后缀表达式的好处是，不用处理优先级和括号，非常方便机器进行表达式求值。
A+B*(C-D)-E/F
则写成:ABCD-*+EF/
因为2个操作数和1个操作符对应。
先把操作数累积在栈里，每读到一个操作符，就抽出两个最近的操作数运算，并把该值压回栈中，作为表达式的一部分继续参与运算。
```
Stack S;
S.top = 0;
elemType Array[] = {ABCD-*+EF/-};
int length = Array.getLength();
for(int i=0;i<length;i++){
    if(Array[i].isOperand){
        S.push(Array[i]);
    }
    if(Array[i.isOperator]){
        int a = S.pop();
        int b = S.pop();
        int value = Op(a,b,Array[i].OpType);
        S.push(value);
    }
}
int result = S.pop();
```


#### 中缀转后缀

a+b-a*((c+d)/e-f)+g
ab+acd+e/f-*-g+

因为中缀表达式存在优先级，这会在栈中体现出来。
乘除法的优先级大于加减。

我们维系一个**操作符栈**。

因为括号内的运算需要一并运算，
遇到**左括号**，入栈，不动。它也不参与优先级比较，只等待着右括号将其删除。
遇到**右括号**，将其与左括号之间的全部运算符出栈。这意味着括号带来的黏着结束了。

当我们读入一个操作符，它的优先级比下面的操作符要高，则暂时在栈中保留该操作符。
这是因为：
优先级高的符号在中缀表达式中**黏着了一大堆表达式**。
所以他会在栈中停留与更多的表达式元素粘合。

如果读入的操作符比下面的操作符优先级低，或者相同，则连带着下面一串优先级高或相等的操作符一同出栈。（如加减）
这是因为：
该符号之前的，较高优先级的黏着已经结束了。是时候将他们输出了。
又或者先前同优先级的计算完成了。


#### 递归

函数的反复递归调用会使程序的栈区大幅增长。

#### Catalan数

n个元素入栈，出栈顺序有以下可能：
该结论由数学归纳法得出。
$\frac{1}{(n+1)}*C\tbinom{n}{2n}$ 

#### 一些小技巧

由于可能性很多，选择题一般只能试。
但出栈顺序的第一个元素是强充分条件。
即，第一个出栈元素确定了，则先于该元素入栈的元素在栈中可以唯一确定。


### 队列

顺序实现：
```
typedef struct{
    int data[size];
    int front,rear;
}Queue;

front一般指向队列头。
rear根据你的喜好，可以指向队尾元素，也可以指向队尾元素的下一个位置。
该结构限制很大。
```

#### 循环队列

所以提出了**循环队列**：
我们约定：
rear指向队尾元素的下一个位置。
并且牺牲一个位置来区分队列满或空
```
#初始：为空
Queue.front = Queue.rear = 0;

#出队列:从队头出
Queue.front = (Queue.front+1)%size;

#进队列:进到队尾
Queue.rear = (Queue.rear+1)%size;

#判断队列元素
int ElementNum = (Queue.rear-Queue.front+size)%size;

#判断队列满
boolean full = (Queue.rear+1)%size == Quere.front;
```

#### 双端队列

允许在队列的两侧都可以入队/出队。
也可以在某一边加以限制，而另一边随意入队出队。
即：输入/输出受限的双端队列：某一段只允许输入/输出

#### 二叉树的层序遍历

我们考虑：
每一个节点以及它的左右孩子都是一个待遍历的节点集合。

如果我们按照这样的规则将节点入队：
默认把**根节点放进队列**。
每次我们访问节点，我们需要以从左孩子到右孩子的顺序在未来访问它下一层的节点。
那么，我们把它的**左右孩子入队**，让他们**在后面排队**，直到当前层的节点完成。
这样累计下去，每一层从左到右的节点都在队列中按照顺序等待着。

```
1.根节点入队
3.若队列空，认为遍历完成。
2.第一个节点出队,遍历它。将其左孩子与右孩子先后入队
```

#### 缓冲区

请注意缓冲区的原理是队列。

### 矩阵存储

#### 对称矩阵/上下三角矩阵

对称矩阵与三角矩阵的压缩存储基础
都基于对**三角矩阵**的行列关系推导。
```
# 以上三角矩阵为例
# 用一行数组存储该矩阵：只存储上三角，下标从0算起。
0:  1 2 3 4 5 有n个元素
1:  0 6 7 8 9 有n-1个元素
2:  0 0 a b c 有n-2个元素
3:  0 0 0 d e
4:  0 0 0 0 f
第i行:有n-i个元素
对于n阶矩阵,i行j列,即Matrix[i][j]
做如下分析:
到达第i行前，已经做了(i-1)行的等差数列求和。
已经过了:(n+n-i+1)*(i-1)/2个元素。
在第i行中:第j列已经经过了(j-i)个元素
求和:index = (2n+i+1)*(i-1)/2 + j-i
得到 array[index] = Martix[i][j]

可以在数组中多给一个位置来存储下三角的单值。

上三角也可以变为对称矩阵的存储：
只需当(i,j)访问下三角时，在计算中对调i与j的位置即可。
```
需要注意的是题目中对于矩阵的行列、与数组的下标，是从0还是1开始。

#### 三对角矩阵
```
#考虑一个这样的带鱼矩阵:
0: 1 2 0 0 0 0
1: 3 4 5 0 0 0
2: 0 6 7 8 0 0
3: 0 0 9 a b 0 第一个元素位于i-i
4: 0 0 0 c d e
5: 0 0 0 0 f x

除了第一行与最后一行，每行元素都有三个。
考虑Matrix[i][j]
i行,则前i-1行有2+3*(i-2)个元素。
j列:j-(i-1)+1=j-i+2个元素。
array[2*i+j-2] = Matrix[i][j];
```

#### 稀疏矩阵

使用三元组:(i,j,value)存储。
三元组既可以采用**数组**存储，也可以使用**十字链表**存储。
**十字链表**在图论中常用来表示有向图。

#### 从地址的角度思考
```
#例题:按行优先存储,每个元素独占一个地址。
A[0][0]的地址是100
A[3][3]的地址是220
求:
A[5][5]的地址:

设长度为N。

#按照地址计算：习惯以地址来进行计算是好的。
&A[0][0] + N 表示&A[1][0],第二串的起始地址。
所以
&A[0][0] + 3*N == &A[3][0] 的地址
&A[3][0] + 3 == &A[3][3]
则100 + 3*N + 3 = 220
N=39

#按照元素个数计算:这个思想更像是在数个数，而不是从CS原理出发。
(220-100+1)个元素 = 3*N+4
N=39。

#最后计算出A[5][5]
A[5][5] = 
A[0][0] + 5*N + 5 = 300

```
起始地址代表着第一个元素。
```
elementType * ptr = 100;
# *ptr == prt[0]
# *(ptr + i) == ptr[i]
```

对地址作差，求得的是两者之间"差了多少"
而两者之间"共有多少"则在加一个。

```
#这个长度代表:该地址距离起始地址差多远,或者多多少
&A[3][3] - &A[0][0] = 120 
#只需再加一个把起始地址的元素也算上，就可以得到总共多少元素。
从A[0][0]到A[3][3]一共有 120 + 1 = 121 个元素
```

要领是，
**数个数**要把握"相差几个"与"一共几个"。
**算地址**就显得更加自然了。
下标从0开始带来的好处就是这种**自然性**。
即A[i]代表距离起始地址A[0]相差了i。
&A[0] + i = &A[i]

## 串

给定一个子串和主串，检查子串在主串中的匹配情况。

### 暴力模式匹配
```
String1: B C A B C B
String2: A B

在两个串中维持两个遍历指针 i与j.
那么匹配的过程中,
i会在String1中一直向后遍历,与String2做比对。
j会在给定的一次比对中,在String2中向后遍历与String1做比对。

如果j成功遍历完成了String2的所有元素，
这说明从String1中的某个位置开始，随着i与j的同时增加，在两个串中，后续"子串长度"个字符完全一致。
则匹配成功。

如果在这个过程中发现i,j匹配失败，那么i回退到刚开始比对的下一个位置，然后继续向后遍历。
而j退回初始位置,进行新一轮的比对。

考虑这样一个情况:
String1长m,String2长n
每次对串的比对过程中,每次都出现:
String2中比对到了最后才发现匹配失败,O(n)
String1退回开始的位置O(1)。
一共进行了m次，时间复杂度为O(m*n),O(mn)
```

### KMP匹配

#### 思想

暴力算法里，每次匹配失败，i 指针都会回到刚开始匹配时的下一位置。
这造成了一定的浪费：
因为在上一次匹配中，我们成功地“**部分匹配了**”一部分子串。
KMP的思想是，虽然在给定位置上整个子串匹配失败，
但是我们得到了**主串上与子串部分匹配的信息**。
我们可以直接把匹配指针挪到恰当的位置，而不是从头重新匹配。
**暴力匹配**浪费了上一次匹配中得到的“**部分匹配**”的信息。

```
String1: A B C A B B X X
String2: A B C A C

#第一次匹配
A B C A匹配成功,C匹配失败

#暴力匹配的情况:
String1: A B C A B B X X
String2:   A B C A C

#KMP匹配的情况:
String1: A B C A B B X X
String2:       A B C A C
```

#### 实现原理

为了实现不靠人工肉眼挪动，而让机器程序也能找到应该移动到的位置，
利用**前后缀匹配**的办法。

将匹配串移动到适合的位置的本质是：使其**子串前缀**与**部分匹配串的后缀**吻合。
如果有多种吻合情况，我们取最长的公共部分。
以String2: A B C A C 为例
我们认为前后缀不能是它自身
```
{A}:        0
{A B}:      {A} & {B} = 0
{A B C}:    {A,AB} & {C,BC} = 0
{A B C A}:  {A,AB,ABC} & {A,CA,BCA} = {A} = 1
{A B C A C}: {A,AB,ABC,ABCA} & {C,AC,CAC,BCAC} = 0
```
在{A B C A}的情况下，前后缀有公共部分A，长度为1.
所以如果j=5时发生了失配，即已知前四个{A B C A}匹配成功，
那么就已知{A B C A C}的头{A}和{A B C A}的尾{A} 匹配成功
```
String1: A B C A B B X X
String2: A B C A x

String1: A B C A B B X X
String2:       A B C A C
```
那么就可以直接把i指针拨到对应位置。
**i向后位移长度**为:部分匹配成功长(j-1) - 对应的公共前后缀长
此时， A B C A部分匹配长度为4,对应公共前后缀{A}长 1
所以i向后移动4 - 1 = 3
**j应拨到**1的位置。

#### 匹配表与next数组

对于给定的一个子串，我们可以提前算出他的所有部分匹配情况对应的公共前后缀长度。
如上一部分给出的A B C A C。
它的**前后缀匹配表**为:{0,0,0,1,0}
称呼词表为**PM表**,*Partial Match*
此表可以直接参与运算。

当C失配，则查看A的值为1.
即失配时查看前一个的值。
那干脆右移一位，图个方便。

即**next数组**:失配时直接读取，就可以得到"当前位置之前部分匹配串的公共前后缀长度"
next1 = {-1,0,0,0,1}
-1意味着，如果第一位就失配，i直接就右移一位。
此时**i向后位移长度**为(j-1)-next[j]


在新一轮的匹配中,j要拨到已经部分匹配的长度+1的位置。因为之前的匹配已经结束了。
所以再整体+1，得到**另一种next数组**，用来指示子串指针j在发生失配时跳转的下一位置。
next = {0,1,1,1,2},得到了j指针的变化公式 j = next[j]
此时**i向后位移长度**为 (s)-(next[j]-1)=**j-next[j]**


得到了j的**next数组**
**i向后位移长度**为(j-1) - 对应的公共前后缀长
如此，指针i与j都可以正确的跳转了。

#### 题目手算

在题目中next数组可能以0开头，也可能以-1开头。区分这两个。

需要掌握部分匹配值表、0开头的next[]与1开头的next[]之间的转换。

**手算PM**(Partial Match)表是容易的。先算PM[]，再右移，后续再加一得到next[]


### 改进KMP算法

此处使用next[]数组以0开始。
考虑这样的串:
```
String1: a a a b a a a a b
String2: a a a a b
unmatch:       x
j:       1 2 3 4 5
next[j]: 0 1 2 3 4 
jump:      a a a a b
j:         1 2 3 4 5
current:       x
nextval: 0 0 0 0 4 (即next[next[j]])
```
失配后,当前j对应的元素a,和之前失配时j对应的元素a相同。
用一个先前就失配了的元素继续比较，必然会继续失配。
我们可以修正next数组为nextval数组。
当出现了这种情况,即String2[j] == String2[next[j]]时
递归地将next[j]修正为next[next[j]]，直到不再相等或者抵达0。
这样**跳过了当前匹配带来的开销**，直接跳转到下一次匹配。 

## 树

### 几个概念


1. **结点的度**
   结点孩子的个数

2. **树的度**
   树中结点的最大度数 

### 树的性质

1. **节点数=节点度数之和+1**
   >该结论源自**图论**：对于**单连通无环图**而言有节点数=边数+1
   简单的证明:该结构下，除去第一个节点，每多一条边就多一个节点。
   所以节点数比边数多1
   注意在数中，结点度数指的是向下的边数，而不是图论中的度数。

2. 度为m的树**第i层至多** $m^{i-1}$ 个**结点**。(i>=1)
   >考虑最多的情况，每一个结点都有m个孩子，即**完全m叉树**。
   **等比数列:** 1, m, m^2, m^3...
   则第i层有:m^(i-1)个节点

3. 高度为h的m叉树**至多**有 $m^h-1/(m-1)$ 个**结点**
   >考虑最多的情况，高度为h的完全m叉树。
   **等比数列求和** : 1+ m+ m^2+ m^3 +...+m^(h-1)
   Sum = 1*(1-m^h)/1-m
       = (m^h-1) / (m-1)

4. 具有n个结点的m叉树的**最小高度**为 $\lceil{\log_m(n(m-1)+1)}\rceil$
   >假设高度为h。
   要令**高度尽可能小**，则该m叉树应尽可能饱满，前h-1层为**完全m叉树的程度**。
   前h-1层满，等比数列求和:(1-m^(h-1))/(1-m) = [m^(h-1) - 1] / (m-1)
   假如第h层满,有:(m^h - 1) / (m-1)个
   则节点[m^(h-1) - 1] / (m-1) < n <= (m^h - 1) / (m-1)
   得到:
   $m^{h-1} < n(m-1)+1 <=m^h$
   取对数,有:
   $h-1<\log_m(n(m-1)+1)<=h$
   对该数字向上取整即得到h

### 二叉树

#### 性质

1. 叶子结点数=度为2的结点数+1
   >由第一节结论1提供的图论思想，非常容易证明。
   二叉树，节点的度为0,1,2。
    $n_0+n_1+n_2= 0*n_0+1*n_1+2*n_2+1 $
    有:
    $n_0+n_2=2*n_2+1$
    故叶子结点数:
    $n_0 = n_2+1$

2. 对结点层序编号，则偶数为左孩子，奇数为右孩子
   >结点*2，即它的左孩子编号。再+1得到它的右孩子编号。
   逆向由孩子得到双亲也是可行的。
3. 完全二叉树给定总结点数，即可唯一确定该树形状。
   >常有**题目**:给定结点数的完全二叉树，问有多少叶子结点。
   h层完全二叉树，它的前h-1层必然满。前h-1层总数确定，最后一层总数也确定。
   则叶子数量确定。
   完全二叉树的题目通常涉及"最多","至少"等。


#### 存储

**顺序存储**：层序编号。
且以1开头，避免编号0导致结点孩子计算公式失效

**链式存储**：
```
typedef struct TreeNode{
    int data;
    struct TreeNode *lchild,*rchild;
}TreeNode;
```
#### 遍历

树的遍历通常是递归的。
层序遍历利用队列，详见队列章节。

Pre,In,Post~Order:
以先序为例。
```
void PreOrder(TreeNode* T){
    #养成好习惯,第一行写递归退出条件
    if(T==NULL) return;

    visit(T);
    PreOrder(T->lchild);
    PreOrder(T->rchild);
}
```
层序遍历:优♀雅
```
void LevelOrder(TreeNode* T){
    Queue Q;
    # T是根节点先入队
    inQueue(Q,T);
    TreeNode * outNode;
    while(isEmpty(Q)==false){
        outNode = outQueue(Q);
        visit(outNode);
        if(outNode->lchild!=NULL)
            inQueue(Q,outNode->lchild);
        if(outNode->rchild!=NULL)
            inQueue(Q,outNode->rchild);
    }
}
```
#### 唯一确定二叉树
给定：
先序+中序，
后序+中序，
层序+中序
序列，
都可以唯一确定一棵二叉树。
总之，要有**中序**。
因为中序的存在使得"根"的位置确定，从而划分了左右子树。
```
PreOrder:  A B C D E F G H I
InOrder:   B C A E D G H F I

PreOrder:  A is root
InOrderL:  B C x
InOrderR:      x E D G H F I
再对这两棵子树分别做同样的分割即可。 
```
>一些想法
我们假设已知一个树的指针,TreeNode * Tree
因为是链式结构，我们不知道整棵树的结构。
那么就需要用其上的方法得到两个序列而确定这个结构。
但既然已经把树抽象为了一个TreeNode* 指针，
也没必要知道这个结构。
如果一定要知道，还不如使用顺序结构用数组存储。
可能的应用是：
在给定序列的情况下建立这一棵树。

### 线索二叉树

二叉树的结构总有大量的空指针，我们期望找到利用这些空指针的办法。

#### 空指针数

一颗有n个结点的二叉树，共有**n+1**个空指针
>证明:
空指针会出现在:叶子结点、度仅1的非叶节点。
则空指针数量=2*叶子结点数+度为1的结点数。
由图论知:该树总度数为n-1
设n0,n1与n2为叶子、度为1的结点，度为2的结点。
则:
空指针数 = 2 * n0+ n1
n0+n1+n2=n,n2 = n - n0 - n1
n1+ 2 * n2 = n-1
Katex表达式:
$\begin{cases}
   n_0+n_1+n_2=n \\
   n_1+ 2n_2 = n-1 
\end{cases}$
$n_1+2(n-n_0-n_1)=n-1$
$2n-2n_0-n_1=n-1$
解得:
$2n_0+n_1=2n-n+1=n+1$

#### 构建

若无左子树，lchild指向前驱。
若无右子树，rchild指向后继。
tag为1认为采用线索。
tag为0表示维持原功能，即指向孩子。
```
typedef struct ThreadNode{
    int data;
    struct ThreadNodee *lchild,*rchild;
    int ltag,rtag;
}ThreadNode;

# 中序 线索化二叉树结点:两两链接。
void buildThreadNode(ThreadNode * T,ThreadNode * pre){
    if(p==NULL) return;

    #左,找向第一个,最左子树
    buildThreadNode(p->lchild,pre);

    #"中"
    if(p->lchild==NULL){
        p->lchild=pre;
        p->ltag=1;
    }
    if(pre->rchild==NULL && pre!=NULL){
        pre->rchild = p;
        pre->rtag=1;
    }
    #线索化完成,pre向后一步。
    pre = p;

    #右
    buildThreadNode(p->rchild,pre);
}

# 中序建立线索二叉树
void rebuildThreadTree(ThreadNode * Tree){
    #一开始没有pre
    ThreadNode * pre = NULL;
    if(Tree!=NULL){ #空指针检查
        buildThreadNode(T,pre); #线索化所有结点
        #最后pre会指向最右叶结点。人工线索化。
        pre->rchild=NULL;
        pre->rtag = 1;
    }
}
```
#### 遍历

找到某元素的前驱与后继:
```
#得到当前子树的最左下元素，它的中序序列第一个结点。
ThreadNode* getFirstNode(ThreadNode * ptr){
    while(ptr->ltag==0) p->lchild;
    return ptr;
}

#得到某节点的后继,是它右孩子中序遍历中第一个结点。
ThreadNode *getPreNode(ThreadNode * ptr){
    if(ptr->rtag==1) 
        return ptr->rchild;
    else 
        return getFirstNode(ptr->rchild);
}

#得到当前子树的最右下元素,它的中序序列最后一个结点
ThreadNode* getLastNode(ThreadNode * ptr){
    while(ptr->rtag==0) p->rchild;
    return ptr;
}

#得到某节点的前驱，是它左孩子中序遍历中最后一个。
ThreadNode * getPostNode(ThreadNode * ptr){
    if(ptr->ltag==1) 
        return ptr->lchild;
    else
        return getLastNode(p->lchild);
}
```

遍历:
```
void InOrderThreadTree(ThreadNode * Tree){
    ThreadNode * ptr = getFirstNode(Tree);
    while(ptr!=NULL){
        visit(ptr);
        ptr = getPostNode(ptr);
    }
}
```

### 鉴定网络热门二叉树选择题

1. 给定遍历序列的题目。

- **类型1**，能确定唯一的二叉树
  该题目非常简单，只需画出所求二叉树，所有问题就都解决了。
- **类型2**，不能确定唯一二叉树
  最常见的题目。使用**排除法**。
  >给定前序序列与后续序列，问中序序列不可能是?
  根据选项给定的中序序列与题目提供的序列可以唯一确定一个二叉树。
  只需把ABCD四个唯一二叉树画出，排除法即可。

2. 一个经典问题:两个遍历序列相同
   >**先序序列**与**中序序列**相同,那么满足什么条件?
   此类问题非常简单。只需做以下分析：
   **根->左->右** 与 **左->根->右** 序列相同，
   只需令左子树消失，即可变成 **根->右**
   所以满足条件:**只存在右子树**。
   给定其他序列也同理。

### 树与森林

#### 树的存储结构

1. **双亲表示法**
   使用数组,逻辑上为二元组(data,parent),parent指向自己双亲的下标。
   根节点的parent设为-1.
   易找双亲，难找孩子

2. **孩子表示法**
   把根节点的所有孩子用链表链接。
   易找孩子，难找双亲

3. **孩子兄弟表示法**
   又叫二叉树表示法。
   每个结点都包括:data,指向孩子的指针,指向兄弟的指针
   可以方便地把树转换为二叉树。
   易找孩子，难找双亲。
```
typedef struct Node{
    int data;
    struct Node *firstchild,*nextBrother;
}Node;
```

#### 树，森林，二叉树

转化的理论依据是:**孩子兄弟表示法**

- **树->二叉树**
  同**孩子兄弟表示法**。
  兄弟连线，指向第一个孩子。
  **左指孩子，右指兄弟。**

- **森林->二叉树**
  森林，即几颗树。而树与二叉树一一对应。
  只需先对几棵树二叉树化，
  再**视树根之间为兄弟**链接即可。

#### 树与森林的遍历

- **先根遍历**: 即 **根->左->右** 二叉树先序遍历不要求二叉的情况。
  其遍历序列与该树所对应二叉树的**先序序列**相同

- **后根遍历**: 即 **左->右->根**。与对应二叉树的**中序序列**相同。
  可以认为,树的"后根遍历","后序遍历" 对应二叉树的"中序遍历"

- **森林遍历**: 即一棵一棵地执行上述遍历。
  森林的**先序遍历**,即执行棵一棵地**先根遍历**。
  森林的**后序遍历**也叫**中序遍历** 对应树的**后根遍历**。

- 总之，只要提到树或森林的遍历，就只有**先根/后根**，对应二叉树的**先序/中序**。

#### 特殊法

- 有一颗2011个结点的树，叶节点有116。
则树对应的二叉树中，无右孩子节点的个数是？
>分析:
二叉树无右孩子节点，即树中无兄弟的结点。
因为树没有如二叉树的限制，可以随便画。
不妨假设:1个根,1894个度为1的中间节点,一个度为116的结点。
所以1894+1=1895

### 哈夫曼树与哈夫曼编码

带权路径最小的二叉树称**哈夫曼树**，或**最优二叉树**。
**WPL** = 叶子结点权值 * 路径长度(走了几条边) 之和

#### 构造哈夫曼树

>每次选定权值最小的两个结点，组成一个新结点，
使这两个节点作为新结点的左右子树。
该新结点的权值为两者权值加和。
并参与新一轮构造，重复。

- 权值越小，离根越远。
- 一共创建了n-1个新的结点。所以结点总数为2n-1
- 新结点都有左右子树。则整颗哈夫曼树都没有度为1的结点。

#### 前缀编码

没有任何一个编码是另一个编码的前缀，称之为前缀编码。

#### 哈夫曼编码

如果路径标识为0与1，树上的抵达不同叶子结点的任一条路径所代表的编码，
必然不会有重叠的前缀。即哈夫曼编码必然是前缀编码。
出现频率、次数、概率越高的字符，离根节点越近。
反之，离根节点越远。

>注:
哈夫曼树新结点的左右孩子可以随便调换，没有要求。
所以构建的哈夫曼树不唯一，可以左小右大，也可以瞎放。
但其带权路径一定是最优的，唯一的。

## 图

### 概念

- 连通分量: 指极大连通子图。

- 强连通: 用于描述**有向图**。任两个顶点之间双向都连通。

- **简单图**: 没有重复边，顶点不到自身。

- **完全图**: 任两个顶点都有边

- 有向图的度数是入度和出度之和

- 生成树: **包含所有顶点**的极小连通子图

- 简单路径: 顶点不重复出现的路径

- 简单回路: 除了第一个和最后一个顶点,其余顶点不重复出现。

### 结论

基本结论**与树的联系**

- **无向连通图**的**度数之和为边*2**
- 树是无向连通图,而树**结点的度**指**孩子的个数**,树的度指结点最大的度
- 除了根,每多一条边就多一个结点,**结点数**=**边数**+1

其他结论

- 无向连通图所有顶点的**度数之和**为**偶数**
  >每一条边对应2个度。必然是偶数。
  即**度数 = 边*2**
  所以无向连通图的度数可以从边算也可以从顶点算。

- 无向单连通无环图,有V = E + 1
- 若无向图 V > E + 1 ,必然不连通

#### 例题

- 无向图G有7个顶点,要保证G**在任何情况下都连通**，至少需要边数?
>在任何情况下，即考虑最坏情况。
考虑:
前六个顶点已经连成了完全图,就差最后一根与第七个顶点相连。
考虑n个人两两握手:
(n-1)+(n-2)+...+2+1 = (1+n-1)*(n-1)/2 = n(n-1)/2
$6*(6-1)/2 = 15$
所以**至少**需要15+1=16条边。

- 无向图G有16条边,度为4的顶点3个,度为3的顶点4个,其他顶点度小于3。至少包含多少顶点?
>至少,让顶点尽可能少，就让其他顶点的度数尽可能大。全取2
$2*16 = 4*3+3*4+2n_2$
$n_2=4$
$n_2+3+4=11$
至少11个顶点。

他们的共性是,根据题里的条件，找出"最好/最差"情况，本质上都是特殊法。

### 图的存储

**邻接矩阵**有天然的直观性，一个二维方阵简单的说明了顶点之间的相通性。
但它太占空间。所以对**稀疏图**提出了用**邻接表**存储。

**给定某一顶点，寻找它的边：**
则邻接表可以直接读取,邻接矩阵需要遍历一行
**给定两个顶点，问之间是否存在边:**
则邻接表要在边表中遍历，邻接矩阵只需读 G[i][j] 看是否连通。

#### 邻接矩阵

整个矩阵，空间复杂度O(n^2),n为顶点数
自己对自己为0
适合**稠密图**
对于无向图而言邻接矩阵是对称的

**一个结论**
>记图G的邻接矩阵为A 则 $A^n$ 的元素 $A^n[i][j]$ 的含义?
由 顶点i到顶点j的长度为n的路径 的个数。

#### 邻接表

在稀疏图的情况下，用邻接矩阵会造成大量的空间浪费
考虑:对每一个顶点都建立一个单链表，链表中为该顶点相邻的结点。
每个顶点作为表头,head
与它相邻的结点插在头后面

```
#边表结点adjacent_Node
typedef struct adjNode{
    int NodeNum;
    adjNode * next;
}

#整个头结点,封装成一个数组,长度为顶点数N
typedef struct headNode{
    int NodeNum;
    adjNode * ptr;
}headNode,AdjList[N];

#可以封装一下
typedef struct AdjListGraph{
    AdjList Vertexes;
    int vertexNum,edgeNum;
}AdjListGraph;
```
无向图空间复杂度为O(V+2*E)
有向图则为O(V+E)
因为无向图里每条边重复了两次

#### 十字链表与邻接多重表

**花里胡哨**

- 十字链表
  不仅给顶点整了个Node,给边也整个Node。
  顶点不仅要指向以它为弧尾的边结点，还要指向以它为弧头的边结点。
  所以非常容易找到以某个结点为头或尾的边。
  表示法不唯一。
- 邻接多重表
  无向图的一种链式存储。
  在邻接表的基础上，把边也整成Node

### 图的遍历

#### 广度优先 BFS

B是Breadth

BFS可以视为二叉树**层序遍历**的拓展。
区别在于为了不让遍历过程往回重复遍历,多了一个visited[]标志位
依然利用了队列:
1. 起始顶点入队列
2. 出队列时访问,修改visited[]标志,并把与之相连且未访问的顶点入队列
3. 重复直至所有顶点都被访问

##### 性能分析

广度遍历需要不断地寻找与某顶点相邻的顶点
广度遍历对每个顶点都执行了：寻找该顶点的相邻顶点
**邻接表:**
适合,每次寻找邻接顶点只需访问边表结点,搜索所有边时间复杂度O(E) 而要搜索V个结点的边O(V)
总时间复杂度:O(V+E)
**邻接矩阵:**
不适合,寻找邻接顶点需要遍历一行,时间复杂度为O(V) ,重复执行V次
总时间复杂度:O(V^2)

因为队列，所以空间复杂度为O(V)

#### 深度优先 DFS

经典递归算法。

1. 从某顶点出发
2. 访问该顶点，设置visited[]标志,继续访问与顶点相邻且为visit过的顶点
3. 若找不到这样的结点，说明当前顶点的更深处已经全都visit过。一种想法是回退，但是细节不好实现。所以考虑对**每个结点**都做一次这样的递归遍历。
4. 重复直到所有的顶点都被visit过

```
int visited[N];

//对某个结点进行深度遍历
//某层递归的退出条件是:读到下一节点是-1 即该顶点的所有邻接顶点都访问过了
void DFS(Graph G,int v){
    //visit访问操作
    visited[v] = 1;
    //当i为-1时说明已经遍历完了 
    for(i=getFirstNeighbor(G,v);i>=0;i=getNextNeighbor(G,v,i)){
        if(visited[i]==0)
            DFS(G,i);
    }
}
//考虑图不是强连通的 有多个连通分量
//那么需要额外遍历visited[]来确定上一轮没有遍历的连通分量
void DFSTraverse(Graph G){
    setZero(visited);
    for(int i=0;i<=G.vertexNum;i++){
        if(visited[v]==0)
            DFS(G,i);
    }
}
```

##### 性能分析

深度遍历同样要寻找与某个顶点相邻的顶点
与广度遍历一样，适合用邻接表。
深度遍历对V个顶点都执行了:寻找该顶点的相邻顶点

**邻接表**:
寻找所有顶点的相邻顶点时间复杂度O(E),访问所有顶点时间复杂度O(V)
**总时间复杂度**O(V+E)

**邻接矩阵**
寻找某顶点的相邻顶点时间复杂度O(V)
做V次,**总时间复杂度**O(V^2)

由于DFS的递归需要在内存中栈区执行，
栈的深度取决于递归了多少次,次数为顶点的个数
即**空间复杂度**为O(V)

#### 邻接矩阵与邻接表的区别

不管是DFS还是BFS
使用**邻接表**的**时间复杂度**都是O(V+E)
使用**邻接矩阵**的**时间复杂度**都是O(V^2)
他们的**空间复杂度**都是O(V)

### 图的应用

#### 最小生成树

**生成树**定义:
包含所有的顶点，并含尽可能少的边
只要再加一条边就会变成回路
只要再减去一条边就会变成非连通图

**最小生成树**:
在边**带权**的情况下，使总权最小的生成树
不唯一

既然最小生成树是简单无环连通图,那么它的总边数是 **顶点数-1**

##### Prim算法

Prim算法是 *加边法*。
最小生成树首先得是一颗生成树。
在生成树的构建中,首先选中某一个顶点
然后加边逐渐扩展到整个图，每次加一条边使得不连通的顶点一个一个加入到已连通的部分
有n个顶点,那就要加n-1条边。
想要得到最小生成树，只需要在**每次加边**的时候选择**最小的边**加入已生成的极大连通子图

时间复杂度O(V^2) 不依赖于E
所以适合求解**边多顶点少**的图
>时间复杂度分析
构建生成树的过程中,每个顶点都要读取它与相邻的顶点之间的距离,取决于O(V)
而V个顶点都这样做:O(V^2)

##### Kruskal算法

Kruskal是 *选边法*

与Prim算法的区别是,
Prim是一点一点构建一颗生成树
Kruskal是通过全局选边凑出一颗生成树。

它的原理是
假如有n个顶点,
如果能保证每次加入的边都不生成回路
则只需加入n-1条边就可以让他们形成一个生成树

所以每次选择整个图中最小的边,过程中如果会造成回路就舍弃选第二小的边。
选n-1次后即可得到最小生成树

时间复杂度O(ElogE) 适合**边少顶点多**的图
>时间复杂度分析
找到当前最小边的过程可以利用堆来比大小,O(logE)
每次选边的过程都要比一次,O(ElogE)
之所以不是O(VlogE)(理想情况,每条边都不产生回路) 是因为可能出现回路,最差情况必须把所有边都检查一次

#### 最短路径

利用广度优先搜索查找最短路径是对于无权图而言
**带权图**求最短路径

DJ只能用于单源最短路径 且边不允许有负权值

Floyd用于求得每对顶点之间的最短路径
允许有负权边，但不允许有存在负权边的回路

##### Dijkstra算法

DJ算法是一种动态规划算法.
维系了两个辅助数组:
dist[]:记录从源点到某顶点的最短路径长度
path[]:记录从源点到某顶点最短路径的前驱结点
用一个集合S来表示已经求得最短路径的顶点集合


**理论依据**:
假如得知了从源点抵达几个顶点的路径长度，
那么其中的**最小值一定为最短路径**:
>源点X抵达:
A 10
B 15
C 20
那么如果X走B或C再抵达A 比X直接走A要远。
可以确定从X走到A这条路径是最短路径。
但X抵达A的路径也可以有很多。所以我们需要**从初始状态一点一点更新**保证求得的最短路径最优。
更新:抵达某顶点的长度取min{走原路径,走上一轮求得的最短路径的长度}
之所以是上一轮是因为上一轮确定的最短路径和这一轮的顶点可以相邻。
已确定最短路径的顶点不再更新


```
1. 确认最初的最短路径
2. dist[]更新取min{原路径,走上一轮的最短路径}
3. 取更新后的dist[]中最小值,可以确定它是最短路径
4. 重复
```

时间复杂度为O(V^2)

##### Floyd算法简介

Floyd用于求得每对顶点之间的最短路径
时间复杂度O(V^3)

但实际上对于单源最短路径(非负权边),
对每个顶点都用一次Dijkstra算法,时间复杂度也为O(V*V^2) = O(V^3)

#### 拓扑排序

**有向无环图**的顶点组成的序列,满足:
1. 每个顶点只出现一次
2. 若A在B前面,就不存在B->A的路径

求序列:不断删去图中没有**前驱的结点**即可

逆拓扑排序就反过来，删没有后继的结点

**判断回路**:
如果删不干净,说明该图没有拓扑排序,说明有环存在。

实现上用栈
把入度为0的顶点入栈
出栈时,它所指向的所有顶点入度-1 再把度为0的顶点入栈
重复
**时间复杂度**:
邻接表:O(V+E) :找V个结点O(V),删边减入度,每次都要遍历边O(E)
邻接矩阵:O(V^2) :找V次结点,每次都遍历一行边

对DFS遍历稍作修改,在递归结束之前输出结点,就可以得到逆拓扑排序。

#### 关键路径

边:活动,表示干活
顶点:事件,表示活干完了
"开始"是活动开始,表示该活动前的事件发生
"发生"是事件发生,表示指向该事件的活动结束

最早发生时间:某个事件最早可以什么时候发生?取决于时间更长的事件
最晚发生时间:在不推迟整个工程完成的前提下,事件最晚可以什么时候发生

同理 活动也有最早开始和最晚开始时间。
活动的时间余量:表示可以拖延多久 如果为0说明任何拖延都会导致整个工程的延后

对于结点(事件):
计算ve(vertex_early):从前往后找,取最大
计算vl(vertex_late):从后往前找,取最小
对于边(活动):
e(early) = 起始结点的ve (最早与前事件一同最早发生)
l(late) = 终点顶点的vl-持续时间 (最晚不能耽误后面事件最迟发生)

若e == l （e-l=0) 说明该边是关键路径

关键路径可以不唯一。对于有多条关键路径的网，
只提高一条关键路径上的速度不能缩短整个工期。

关键路径是从源点到汇点路径长度最长的路径
增加任意一个关键活动的时间会延迟工期，
而缩短任意一个关键活动的时间不一定会缩短工期。

## 查找

### 平均查找长度ASL

ASL = $∑C_iP_i$ 是**期望**,是加权平均值
$E(C),C:\begin{Bmatrix}c_1 & c_2 &c_3 & ... \\p_1 & p_2 &p_3 &...\end{Bmatrix}$
$E(C) = ∑ Count*Possibility$
其中$P_i$为查找第i个元素的概率$∑C_i$为该元素需要的比对次数
>对于等概率查找
如一个长度为n的顺序表,因为可以随机存储
其$P_i = \frac{1}{n}$
则:ASL = $ \frac{1}{n} ∑C_i = \overline{C}$
此时才为均值 题目一般都是等概率的
通常直接:总查找次数/个数

### 二分(折半)查找

**二分查找(判定)树**:是一颗**平衡二叉树** 也是**二叉排序树**(左小右大中序有序)
有成功与失败结点
二分**查找的次数**:最多不会超过**树高**

树高计算:
>不妨认为前h-1层位满二叉树
$(1+2+4+...+2^{h-2})=\frac{1*(1-2^{h-1})}{1-2}=2^{h-1}-1$
$2^{h-1}-1 < n \leq 2^h-1$
$2^{h-1} < n+1 \leq 2^h$
$h-1 < log_2{(n+1)} \leq h$
$h = \lceil log_2{(n+1)} \rceil$
故折半查找的时间复杂度为**O(logn)**

题1
>长度16的有序表,二分查找最多执行几次比对?
即求树高(不算失败结点)
1 + 2 + 4 + 8 =15
第五层加一个:树高5层 所以最多执行5次比对

题2
>给树形,问哪个可以是二分查找的判定树
首先二分查找是二叉排序树
所以按照**中序编号**
然后查看该编号是否符合二分查找
通常用**取整不统一**来否定

### 树形查找

#### 二叉排序(查找)树

左子树小,右子树大
则**中序序列**有序(从小到大)

若**平衡** 平均查找长度为**O(logn)**,同二分查找
**最差**情况下可达到**O(n)**

插入与构建:按照路径插入即可

**删除:**
- 被删除的结点无子树:直接删了
- 被删除的结点有1子树:用子女填补其空缺
- 被删除的结点有2子树:找**右子树的中序第一结点**填补:保证填充上去一个刚好最接近但大于被删除结点的结点


#### 平衡二叉树

左右子树高度相差不超过1的**二叉排序树**

**平衡因子**:左子树高 - 右子树高

在二分查找处已证明:
平均查找长度为**O(logn)**
树高$h = \lceil log_2{(n+1)} \rceil$

##### 构建与插入

构建平衡二叉树的过程就是不断插入新结点的过程

**旋转类型**:Left和Right
- LL 即插在不平衡结点的左孩子的左孩子
- RR 即插在不平衡结点的右孩子的右孩子
- LR 即插在在不平衡结点的左孩子的右孩子
- RL 即插在在不平衡结点的右孩子的左孩子

对于LL与RR旋转比较简单，只需进行**一次旋转**即可在满足大小顺序的情况下使其平衡.
- LL意味着左边高右面低,右单旋转一次
- RR意味着右边高左边低,左单旋转一次

对于LR与RL旋转则需要**两次旋转**,第一次旋转用于调整大小位置,第二次旋转完成平衡.
- LR 即先左旋调整不平衡结点左子树的结点位置 再右旋整体使其平衡
- RL 即先右旋调整不平衡结点右子树的结点位置 再左f旋整体使其平衡

不管是LL RR LR与RL都有可能在旋转过程中**挤掉一个结点**,同时一个结点多出一个孩子位。把被挤掉的结点接到这个多空出来的位置即可
注意单旋和双旋旋转的位置

##### 删除

一般删叶子结点。同理进行LL RR LR RL旋转
转就完事儿了

#### B树和B+树

##### B树

B树是**平衡因子为0**的平衡查找树
B树m阶,指m路平衡查找树,**m叉树**
每个结点至多m个子树.子树的树杈从数字之间延伸出,表示介于两个数字之间.
所以m-1个关键字,延伸出m棵子树.

- m阶B树为**m叉**平衡查找树,每个结点**至多m-1个**关键字
- 若根节点不是叶节点,至少有两颗子树 即不对根做均匀散布的要求
- **除根之外**的分支节点,至少有 $\lceil m/2\rceil$ 棵子树,即至少有 $\lceil m/2\rceil-1$个关键字:保证"索引分支"尽可能**均匀散布**到整棵树,所以每个结点至少要有$\lceil m/2\rceil$个子树
- 均匀散布的要求带来了关键字个数的**下限**: $\lceil m/2\rceil-1$ 
- m叉树的要求带来了关键字个数的**上限**:m-1

即m阶B树:
分支节点**关键字个数范围**在 $\lceil m/2\rceil-1$ ~ $m-1$
根节点:2~m棵子树, 1 ~ m-1个关键字

B树的高度决定了硬盘存取的次数
B树的叶子结点是虚构的,实际上不存在.所以说叶子结点不携带信息
不能说B树在做索引 因为找到最后的叶子结点,认为查找失败

##### 插入与删除

若插入某结点后关键字个数溢出,
则进行分裂,将中间位置$\lceil m/2\rceil$放进父结点

若删除某关键字后个数不够
则能借兄弟就借兄弟 兄弟不够借则父结点下来一个

>**关于借兄弟与合并**
题目喜欢出不可能调整后不可能是关键字序列的是
通常突破口在于借兄弟或合并结点要符合大小顺序
题目可能在小位置借来了大兄弟
也可能把小结点合并到了大结点中 导致顺序错误

##### B+树

- B+树的关键字与分支结点一一对应
- 至少$\lceil m/2\rceil$个关键字,至多m个关键字 $\lceil m/2\rceil$ ~ m 
- 叶子结点用指针从左到右,从小到大链接
- 所以叶子结点携带信息 包含所有的关键字
- 所以B+树是在做索引 因为最后能找到东西

##### B树总结
- 分支节点子树范围 $\lceil m/2\rceil$ ~ $m$
- 根节点棵子树范围 $2$ ~ $m$
- 借兄弟与合并:注意大小顺序

#### 散列表

散列表即建立映射关系:关键字与其存储地址的映射关系

散列表的构造方法:
- 直接定址法:取线性关系 Addr(key) = a * key +b
- 取余数: Addr(key) =  key%p 选一个较好的p
- 数字分析法 sb
- 平方取中法 sb

##### 处理冲突:

- 开放定址法
  线性探测:冲突了按顺序向后找,最后一个表项的下一个回到开头
  平方探测:避免大量元素在相邻位置堆积,取平方位置
  双散列:整两个散列函数 第一个冲突用第二个

- 拉链法
  把冲突的链接起来建立一个散列表

##### 性能分析

ASL:各关键字的比较次数的加和/个数 **(查找成功)**
$α$,装填因子表示一个表的装满程度 越满,越容易冲突

在查找时,我们在查找什么?
>给定一个数,我们期望由该数得到一个地址
我们会根据散列函数求得一个地址位置.
我们期望能在这个位置得到这个数
如果冲突,我们期望能在这个位置的后续找到该元素
当查完了所有元素发现并不存在该元素,认为**查找失败**

- 装填因子,散列函数,冲突解决策略都会影响ASL
- 为了提高查找效率,应尽可能避免冲突,处理冲突时避免聚集
- 堆积会影响平均查找长度:会使得临近的冲突元素查找时不停地向后寻找

##### 查找失败ASL

> 题目
表长11 H=key%7, keyword:87,40,30,6,11,22,98,20,查找失败的ASL
首先keyword用于建表
得到如下散列表
```
0  1  2  3  4  5  6  7  8  9  10  11
98 22 30 87 11 40 6  20 -  -  -   -
```
>所以对于H= key%7 查找位置是0~6 7个位置
考虑查找一个散列值为0的关键字
若要查找失败,则要比对0~8 9次
同理查找到6,比对6~8 3次
我们不会查找到7
所以ASL=(9+8+7+6+5+4+3)/7=6

## 排序

|排序|最好时间复杂度|最坏时间复杂度|稳定性
|:-|:-|:-|:-|
插入排序|O(n)|O(n^2)|稳定
希尔排序|O(n)|O(n^2)|不稳定
冒泡排序|O(n)|O(n^2)|稳定
简单选择排序|O(n^2)|O(n^2)|不稳定
快速排序|O(nlogn)|O(n^2)|不稳定
堆排序|O(nlogn)|O(nlogn)|不稳定
二路归并排序|O(nlogn)|O(nlogn)|稳定

不稳定: 希尔,简单选择,快排,堆
稳定：插入,冒泡,二路归并


### 直接插入排序

维持前面的子序列有序 插入时可能要整体移动数组
```
//A[0]用作哨兵,没必要
//从小到大
void insertSort(int array[],int n){
    //array[0]作为哨兵,不存元素
    //array[1]~array[n]共n个元素
    for(int i=2;i<n+1;i++){
        //A[i-1]代表有序表中最大元素
        if(A[i]<A[i-1]){
            A[0] = A[i];
            for(j=i-1;A[0]<A[j];j--){//大的向后移动一格
                A[j+1] = A[j];
            }
            A[j+1] = A[0];
        }
    }
}
```
```
//无哨兵版 从小到大
void insertSort(int array[],int n){
    for(int i=1;i<n;i++){
        if(A[i]<A[i-1]){
            int temp = A[i];
            for(int j=i-1;A[j]>temp;j--){//大的向后移动一格
                A[j+1] = A[j];
            }
            //移动到了某个位置,A[j]已小于temp
            A[j+1] = temp;
        }
    }
}
```

还有一种折半的插入排序
它仅**减少了比较元素的次数**,并没有改进时间复杂度

### 希尔排序

属于插入排序
分割待排序表为:[i,i+d,i+2d,...,i+kd]
执行若干趟,每趟取不同的间隔.
在一趟中,根据d可以划分间隔为d的元素为若干组
**组内**进行**直接插入排序**

### 冒泡排序

```
如果从前向后两两比较,每轮最终位置确定在最后面
从小到大:
void bubbleSort(int array[],int n){
    for(int i=0;i<n;i++){
        for(int j=1;j<n-i;j++){
            if(array[j]<array[j-1]){
                int temp = array[j];
                array[j] = array[j-1];
                array[j-1] = temp;
            }
        }
    }
}
```

### 快速排序

思想是选一个pivot当成分界点 分治递归
```
//一轮partition最终确定当前pivot的位置
int partition(int array[],int low,int high){
    int pivot = array[low]; //选第一个当pivot 当然也可以选别的
    //此时array[low]被pivot保存下来,我们认为array[low]这一位置空了出来,用来来回倒腾元素
    while(low < high){
        while(low<high && array[high]>=pivot){
            high--;
        }
        //此时交换并换到另一边
        A[low] = A[high];
        while(low<high && array[low]<=low){
            low++;
        }
        A[high] = A[low];
    }
    A[low] = pivot;
    return low;
}

//low与high会逐渐向中心靠拢,在这个过程中左右来回倒腾大小元素
//当low与high相遇时,代表这个位置是pivot,其左面都比pivot小,右面都比pivot大
//只需对其左右再递归进行划分,最终就可以得到全局有序序列
```

```
void quickSort(int array[],int low,int high){
    //递推退出条件 等于说明子序列已经收敛
    if(low>=high) return;
    //先进行一次划分,得到中间的pivot位置
    int pivotPos = partition(array,low,high);
    //再递归对左右划分
    quickSort(array,low,pivotPos-1);
    quickSort(array,pivotPos+1,high);
}
```
**性能分析**:
所选pivot会落在最终位置。
分治,最理想的情况是每次划分都最平均,划分O(logn) 每次划分要比较O(n) 故最优O(nlogn)
则当排序表**基本有序或者逆序**时 情况最坏O(n^2)因为最不平均(选第一个为pivot)

>不可能是快速排序第二趟排序结果的是:
3 2 5 4 7 6 9
每一趟快速排序都会确定一个pivot,使左小右大或左大右小
这样的序列找不到2个满足pivot的数字


### 简单选择排序

有手就行

```
//从小到大
void selectSort(int array[],int n){ 
    for(int i=0;i<n;i++){
        for(int j=i+1;i<n;j++){
            if(array[i]>array[j]){
                int temp = array[i];
                array[i] = array[j];
                array[j] = temp;
            }
        }
    }
}
```

### 堆排序

视堆为一颗完全二叉树
大根堆:根大于孩子
小根堆:根小于孩子
输出时，总是和最后一个元素交换。

#### 排序原理

每一轮排序都根据堆顶是最大/最小元素的性质输出，并交换最后一个元素到堆顶。这一行为同时破坏了堆的性质，所以每一轮输出后都要伴随一次重新调整，使其重新恢复为堆。

#### 堆的构建与调整

由于堆是完全二叉树，所以非常适合顺序存储，一个堆实则就是一个数组。  

要对一个这样的数组进行堆排序，首先他得是个堆。所以我们需要调整这个数组，使其符合堆的性质，即建堆。  
建堆是通过倒着从叶子结点向前逐渐调整子树性质实现的，调整的结点可能继续下沉。经过了严格的数学证明，建堆的时间复杂度为O(n)。

当它已经是个堆，我们可以对其进行排序了。每次都输出堆顶，并与最后一个元素交换，输出后我们就固定了一个最大元素/最小元素。最后一个元素被交换到堆顶，需要将其逐层交换下沉重新调整为堆。由于这个数组已经是堆的形式了，所以这个步骤是容易的。  

每次调整的时间复杂度取决于树的高度，由完全二叉树知O(logn)。
我们需要输出n个元素，则对堆排序的时间复杂度为O(nlogn)。  

对于一个一般数组，将其进行堆排序的总时间复杂度为O(n) + O(nlogn) = O(nlogn)

#### 应用

适用于关键字较多的情况
>如何在1亿个数中选出前100个最大值
先拿100个数 在大小为100的数组建立一个小根堆
此时这100数里最小的在堆顶
只需把这1亿个数挨个与堆顶比较
如果比堆顶还小,说明一定不是前100个最大的
如果大于等于堆顶,说明该元素有可能成为前100个最大的数,而比它小的堆顶元素首先比它下面99个元素小，又比这个数小，它必不可能是前100个最大的。所以输出堆顶，用该数字顶上，重新调整。
把这1亿个数全过一遍，最后留在堆里的100个数就是最大的100个
**一言以蔽之，我们在筛去堆顶的较小值，直到只剩下100个较大值。**

>n个数保存在一维数组M中 查找M中最小的10个数 设计算法 说明平均情况时间复杂度与空间复杂度
建立大小为10的大根堆 遍历 同上一问
时间复杂度:O(n)
要遍历n个数,O(n)
而调整取决于数高O(h) 为常数3或4 则时间复杂度O(n*C) = O(n)
空间复杂度O(1) 多用了大小为10的数组

### 二路归并排序

虽然也可以用于内部排序
但通常用于外部排序 大文件合并
思想是左右分别有序，二合一
一直左右二分分治直到收敛

```
//认为左右两个有序表 进行二合一
void Merge(int array[],int low,int mid,int high){
    //辅助比较数组
    int *temp=(*int)malloc(sizeof(array));
    for(int i=low;i<=high;i++){
        temp[i] = array[i];
    }
    int leftPtr = low;
    int rightPtr = mid+1;
    int k = 0;
    while(leftPtr<=mid && rightPtr<=high){
        if(temp[leftPtr]<=temp[rightPtr]){
            array[k] = temp[leftPtr];
            leftPtr++;
            k++
        }else{
            array[k] = temp[rightPtr];
            rightPtr++;
            k++
        }
    }
    //此时可能有未检测完的部分 直接输入就行
    while(leftPtr<=mid){
        array[k++] = temp[leftPtr++];
    }
    while(rightPtr<=high){
        array[k++] = temp[rightPtr++];
    }
}

//现在只需递归调用即可
void mergeSort(int array[],int low,int high){
    //递归退出条件 相等时递归已收敛
    if(high>=low) return;
    int mid = (low+high)/2;
    mergeSort(array,low,mid);
    mergeSort(array,mid+1,high);
    Merge(array,low,mid,high);//在收敛处发挥作用
}
```






