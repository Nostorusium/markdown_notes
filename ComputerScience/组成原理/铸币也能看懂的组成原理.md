# Some perspectives from Computer Organization and Design

## 运算

### 为什么是补码?

计算机程序对正数和负数都要进行计算，所以需要一种方法来区分正数和负数。
最显而易见的方法就是加一个符号位，而一方面将符号位放在哪里存在争议，而且在带有符号位表示的数中会同时出现正零与负零。这会给程序员带来负担。于是加符号位方案很快被放弃了。  

在研究其他方案是产生了这样一个问题：当用一个很大的数去减一个很小的数，将造成前面的位都变成了一串1。在没有更好选择的情况下，最终解决方案采用了这样一个易于计算机实现的方式：前导位为0表示正数，前导位为1表示负数。即计算机补码，Two's Complement。  

要计算一个补码的相反数有一个窍门：  
一个数与它每一位取反之和为：1111...1111 即-1  
那么 $ x+ x_{取反} = -1$ , $ x+ x_{取反} + 1 = 0$  
于是 $ -x = x_{取反} + 1$  

### 为什么偏移寻址？

考虑一个MIPS条件分支指令：

```
|   ..   |  ..  |  ..  |    Exit    |
|  6bit  | 5bit | 5bit |    16bit   |   total:32
```

如果程序地址由该16位地址指定，这意味着任何程序都不能大于2^16  
另一个办法是用一个寄存器+该指定地址得到最终地址。即偏移寻址。  
对于分支预测而言，大概一半的条件分支的跳转范围都在PC值附近，因此通常采用程序计数器偏移。
于是我们得到了PC相对寻址，MIPS对所有条件分支都是用PC相对寻址，他们的跳转目标一般比较接近当前PC，即当前分支指令本身。

### 怎么乘法

```
      1000
    x 1001
----------------
      1000
     0000
    0000
   1000
----------------
   1001000
```

如果没有相关硬件支持，不妨将1000加1001次。  

在ALU，位移器，寄存器的硬件支持下，可将这个竖式乘法转化到硬件结构上：  
被乘数寄存器: 1000  
乘数寄存器: 1001  
乘积寄存器: 0 并逐次累加.  
每次取乘数的最低位与整个被乘数运算。如果是0，说明结果是0，直接进入下一轮。如果是1，则进行运算。  
由于结果需要累加到高位，所以此时将乘数左移一位，以便让它加到更高的位置。  

摩尔定律为我们提供了非常充足的资源，硬件设计者可以设计更快速的**乘法器**。比如：为乘数的每一位都配备加法器进行二分加速，甚至更快、易于流水线的方式。  

### 浮点数

浮点数，就是科学计数法。所谓的规格化浮点数，其实是规格化科学计数法。  

对于一个规格化的科学计数法表示的数，要求小数点前只有一位，且不为前导零。  
如 $1.0_{10}*10^{-9}$ 是规格化的，而 $0.1_{10}*10^{-8}$ 与 $10_{10}.0*10^{-10}$ 不是。

一个浮点数由符号位，指数Exponent和尾数Fraction构成。指数会增加数的表示范围，尾数将会增加表示精度。因此浮点数必须在两者之间取一个折中。  

**单精度： 1符号位  8指数位   23尾数位**  
**双精度： 1符号位  11指数位  52尾数位**  

于是一个浮点数表示为： $ (-1)^S*F*2^E $  

因为规格化一定是前导1的，所以 IEEE754 甚至隐藏了这一位1，来将更多数据位打包到有效位数。于是单精度的数宽其实有24位(+1),双精度由53位(+1)。
此时一个浮点数表示为： $ (-1)^S*(F+1)*2^E $  

IEEE754的设计者希望浮点能够比较处理排序比较，因此在浮点数结构中，先出现符号位，然后出现指数位与尾数位。
而现在仍有一些问题：当我们采用补码或者其他编码时，可能造成指数位的最高位是1，从而导致一个负的指数看起来很大，这又不利于比较了。比如：

```
S  |           E             |       F
31 | 30 29 28 27 26 25 24 23 | 22 21 20 ... 0
0  | 1  1  1  1  1  1  1  1  | 0  0  0  ... 0
```

该浮点数为 $1.0_2*2^{-1}$

```
S  |           E             |       F
31 | 30 29 28 27 26 25 24 23 | 22 21 20 ... 0
0  | 0  0  0  0  0  0  0  1  | 0  0  0  ... 0
```

该浮点数为 $1.0_2*2^{+1}$
在比较E时，看起来很大的数反而比一个看起来很小的数要小。  
因此我们更希望计数法能够把最小的负指数表示为000..000，最大的正指数表示为111...111的形式。于是放弃补码，引入一个偏移实现，该计数法称为带偏阶的计数 biased notation，或**移码**。用真实指数+偏移值后的值取代原指数部分。

IEEE754规定单精度偏阶为127(01111111)，双精度为1023。  
此时，浮点数表示为： $(-1)^S *(1+尾数)*2^{指数-偏阶} $  
原-1将表示为+126，原+1表示为+128.  

单精度表示范围为：
$ ±1.000...000 * 2^{-126} $ ~ $ ±1.111...111 * 2^{+127}$  
8位移码可表示(0 ~ 255)，而指数部分全0与全1都表示有特殊意义。  
于是指数部分的实际取值是(1 ~ 254)，对应真实指数(-126 ~ +127)  
偏移量取127，正好得到 (-126 ~ 0) 和 (1 ~ 127) 两个均匀分布。这也是为什么不用128作为偏移。

### 浮点规格化与特殊意义

将 $0.2*10^{-7}$ 规格化为 $2.0*10^{-6}$ 即向左规格化。  
该过程可能持续多次，每次都需要令尾数左移1位，让阶码-1  
  
将 $20.0*10^{-9}$ 规格化为 $2.0*10^{-8}$ 即向右规格化。  
当尾数发生了进位，则只需右规一次，令尾数右移1位，阶码+1  

当尾数取零，阶码取零，则表示正负零。  
若尾数取零，阶码取全1，则表示正负无穷。  
对于尾数不为零，而阶码为0，说明该数成立，但是没有规格化。对于未规格化的数，不采用隐藏1。  
若尾数不为零，而阶码为全1，表示NAN  



### 标志位

- ZF zero flag 零
- OF overflow flag 有符号-溢出
- SF sign flag 有符号-最高位符号为1，则为1
- CF carry flag 进/借位

众所周知机器级分支判断可以使用标志位进行算术判断。  
无符号数A-B:  
- A=B ZF=1
- A>B ZF=0,CF=0
- A>=B CF=0
- A<B ZF=0,CF=1
- A<=B ZF=1 || CF=1

### 类型转换

> CSAPP:
  C语言当涉及到有符号数和无符号数的运算，会隐式地将有符号数转换为无符号数。  

对于计算机而已一律按照补码方式计算数据，有符号和无符号只是对该数据的解释不同。


## 存储器

### RAM

重申一下其全称为Random Access Memory 与 Read-only Memory。  
内存主要采用DRAM，Dynamic RAM。  
靠近处理器的cache主要采用SRAM，Static RAM。  
区别于ROM，RAM都是易失的，不持续供电就会失去信息。  

DRAM使用电容保存电荷，所以不能长久地保存数据，必须周期刷新一下，于是得名动态。而SRAM不需要刷新，因此称静态。  

由于DRAM需要频繁刷新，因此采用了一个更高效的两级译码结构，在一个读周期后紧跟一个写周期一次刷新一整行，一行单元共用一个字线。  

> 16M*8的DRAM芯片，需要多少地址线和数据线？
> 16M = 2^24 = 2^12 * 2^12，即该DRAM有 2^12 行 2^12 列个块，每块存8bit，每次访存可访问一行/一列。
> 则访问到一块只需要2 * 2=4地址线，数据线8。

### ROM

ROM和RAM都采取随机存储的访问方式。读效率远高于写效率（如果可以）。  

- 闪速存储器Flash Memory由Intel在90年代发明，既又EEPROM的特点（断电不损失），又有RAM的特点（可擦写），相当于硬盘。主要用于U盘，存储卡等。
- 固态硬盘Solid State Drive则是基于闪速存储器制作出来的。
  
闪存和SSD都属于广义上的ROM，但又没有保留其只读的特性。

### 天下无敌的cache与映射原理

当我们谈论缓存，我们主要关注两个层次的存储器之间交换数据。在这样的一个二级层次结构中，我们称存储信息的最小单元为块(block)或者行(line)。在层次与层次之间复制按照块进行。

cache作为缓存应当有以下一些结构：
1. 缓存的数据部分
2. 缓存块的索引
3. 可能的额外控制位(有效位)

此外不同地址可能映射在同一个cache块上，我们还需要一些字段来确认具体存储在该cache块中的数据是否是我们需要的字。于是还需要标记位字段。  

以直接映射为例，假如cache大小为8，内存地址大小为5bit。  
我们对长度为5的地址进行模8，即取末三位映射到cache中，所以地址的末三位作为索引位。  

````
index | valid | tag |  数据
000       Y     11    Memory(11000) 
001       Y     11    Memory(11001)
010       N     -     -
011       N     -     -
100       N     -     -
101       Y     01    Memory(01101)
010       N     -     -
111       N     -     -
````

这意味着地址00000 01000 10000 11000都映射到索引为000的cache块。
我们取剩余的前两位作为tag标记位，这样通过cache的标记位，我们得知该索引对应的cache块到底来自哪个地址。  

cache的索引与标记位唯一确定了其存放内容的主存地址。索引位并不作为cache一行条目的组成。  

我们目前关注的是一个二级结构之间的数据交换，我们以块为单位进行数据交换，索引是以块为单位的索引。假如cache有n个块，他可以映射到2^n个实际块。索引位要有n位。一个块的大小为m个字节，那么一个块的块内偏移需要m位。
那么一个地址可以解析为这样：

```
剩余标记位 | n位索引 | m位块内偏移
```

较大的块可以更好的利用局部性，降低不命中率。可是过大的块会造成cache块数的降低，造成大量的映射竞争，块被频繁换出，不命中率反而上升。块过大的另一个问题是，缺失代价会随着块的增大而增大。当块过大，不命中代价会超过缺失率的降低。  

### 更灵活地映射cache

直接映射是一个极端的映射方式，此时一个块被精确地放到一个位置。  

另一种极端方式是：允许任意一个块映射到任意一个位置，即**全相联**(fully associative)。但由于任何块可能在cache中的任何一个位置，你需要检索整个cache。因此全相联只适合块数较少的cache。  
由于全相联模式中块的映射位置不确定，所以不需要索引号。

介于两者之间的这种方案就是**组相联**(set associative)。在这个模式下每个块的映射位置数是固定的，根据索引字段块被映射到cache的某一组，而在组内进行全相联。在这个模式下，包含存储块的组是这样映射的：(块号)mod(cache组数)。  

提高相联度确实可以降低缺失率，但也意味着命中时间的增加。

### 虚拟内存

就如同cache的原理一样，我们可以使用内存作为磁盘的缓存。  
由于历史原因，在这里块被叫做页，缓存不命中即页面不命中。  
当缺页发生，通常由操作系统的异常机制处理，OS获得控制权后转而执行缺页处理程序。  

一个程序的状态(state)可以由其页表，PC，寄存器表示，这个状态即进程process。  
- PC表示了该程序执行的位置
- 寄存器/trapframe表示了当前程序的一组状态值
- 而页表则表示了这个进程的地址空间与它可以访问的所有数据。

操作系统只负责将进程的页表位置载入页表基址寄存器，而不保存整个页表。由于不同进程使用相同的虚拟地址，他们的页表应当是各自独立的，由调度时载入不同进程的独立页表。  

OS会创建一个数据结构记录所有虚拟页在磁盘上的存放位置，他可能是页表的一部分，也可能是辅助数据结构。页表记录的页可能已载入内存，也可能仍停留在磁盘上没有载入。在逻辑上这两部分页是一个表，而实际上保存在两个独立的数据结构中。

### 直写和写回

cache和主存的写时间相差上百个时钟周期。而主存和磁盘的写时间相差数百万个周期。  
因此在面对一致性问题时，cache与主存之间采用直写机制，而主存和磁盘直接采用写回机制。 

对于cache与主存之间，如果仅仅是wrtie through仍然很慢，一个解决办法是采用**写缓冲**。当一个数据在等待被写入主存，先将其加入写缓冲区，然后继续执行。如果写缓冲区已满，则处理器必须阻塞并等待其不空。  

即便有写缓冲区，如果存储器完成写操作仍然比处理器产生写操作要慢，写缓冲区总会有堆满的时候。为了避免阻塞，通常需要增加写缓冲区的深度。  

写回即只修改在已在内存中的页，在该页将要被换出时再复制到磁盘去。

### 快表TLB

要访问一个虚拟地址，我们至少需要两次访存：
1. 通过页面机制寄存器，得到页表的物理地址，继而由该地址访存获得页表，并获得页表给出的地址转换信息。
2. 获得了页表信息后，虚拟地址经过地址翻译得到物理地址，继而访存第二次，即真正的地址。

虚拟地址的虚拟页号也有局部性，利用它我们建立了快表TLB，或者将其称为地址变换高速缓存。TLB将作为页表的cache，与cache保持类似的结构，同样拥有标记位，有效位和其他控制字段。此时，虚页号将作为索引位。

> 页表包含了所有虚拟页的项，不同于cache是一种取模部分映射，页表不存在标记位，所以也称不上cache

### 从地址翻译到缺页到访存

地址翻译在真正访存之前。TLB通常存在于地址翻译单元MMU之中。因此当CPU获得了一个虚拟地址需要经过如下流程：
1. 得到虚拟地址后需要先访问页表获得物理页号，而TLB作为页表的缓存，先试图访问TLB。
2. 如果TLB命中，则直接翻译成功，直接进行访存即可。如果TLB不命中，则需要真正访问页表。
3. 访问内存，获得页表信息。
   如果页表中，虚拟页的有效位为0，说明该页没有载入内存，进行缺页处理后进行访存。
   **缺页处理**需要先通过虚拟地址在磁盘上找到该页位置，随后进行页面置换。如果被换出的页面被修改过还需要进行写回。
   置换后，换出物理页面被换入的页取代，加入TLB，**然后直接访问TLB**直接命中继而访存。
4. 页表中，如果该虚拟页的有效位为1，说明已在内存中，进行地址翻译并准备访存。
5. 该页存在于内存中，先查看cache，若cache命中，直接读取。若不命中，则真正访问该内存地址并载入cache。

cache根据不同的设计，既可以使用物理地址，也可以使用虚拟地址。

### Cache具体长什么样

而对于一个地址，我们可以将其分割为：
```
tag | index | 块内偏移
```

其中index作为cache的索引，但并不作为cache的组成。如果采用了全相联，则这个地址也不需要index索引了。对于一个一般的cache，长这样：

```
有效位 | 脏位 | LRU位 | tag | 块数据
```

- 有效位，简单的标注cache的有效性。
- 在使用写回法时引入脏位。如果cache采取写回法，在cache被CPU写过后将该位设置为1。在cache块换出时检测写回。
- LRU标记位： 如果cache采取LRU替换策略，需要 $log_2n$ 位LRU替换位。即能够表示替换组内那一块。（n为组内块数，如四路组相联，4=2^2 则有2位）

### DRAM主存

内存条通常是若干个DRAM芯片构成的。对于一个DRAM芯片而言，他是若干行若干列存储单元构成的阵列，要访问一个单元，我们通常要给出行与列。  

但DRAM采用行列复用技术，DRAM的行与列通常由总线的不同时期给出，这意味着我们可以砍掉地址引脚的一半，而多花一个周期分开传送行列。

如:
```
8192 * 8192 * 8位的DRAM芯片
8192 = 2^13, 通常行列需要13位，一共26位。
当引入复用后，砍掉一半，只需13位。
```

DRAM的访问，一次可以激活一行。DRAM通常会为一行数据准备行缓冲区。  
而DRAM是行优先的，无法一次激活一列，也没有列缓冲区。

### 多模块交叉编址

多模块交叉编址的核心思想是把主存划分为多个彼此独立，有良好并行性的模块。  
在引入了这个技术，一个数据就不再被连续的分配在同一个模块的连续位置，而是分散到不同模块之中去。例如:

```
offset 0 1 2  3
M0:    1 5 9  13
M1:    2 6 10 14
M2:    3 7 11 15
M3:    4 8 12 16
```
每个内存模块都有自己的存储区域和数据缓冲区，我们可以认为他们能够独立工作。几个模块之间的激活有时序要求，按周期激活。
多模块交叉编址的目的之一，是把访存分布到多个独立的内存模块上，而达到平衡负载与数据并行性。每个内存模块只能在一个时钟周期内处理一行数据，倘若交替调度这些模块，我们可以实现在同一时刻内实现多个模块的并行工作。  

## 指令系统

### CPU类型

在对待指令上，CPU可以分为两类：
1. 单周期CPU，力求一个时钟周期完成一个指令，CPI=1。
2. 多周期CPU，允许一个指令由多个周期完成，CPI>1。
   在引入流水线后，理想情况下CPI=1。

### 变长指令

要保证边长指令，至少保证前缀不重合。  
要保证前缀不重合，只遵循一个原则：111...110 与 111...111 前缀不重合。

以下面为例：
```
0000~1110 15条： OP A B C
0000 A B C
0001 A B C
...
1110 A B C
-------------
0000~1101, 14条 OP A B

1111 0000 B C
1111 0001 B C
...
1111 1101 B C
-------------
10 0000~11 1110, 31条 OP A
1111 1110 0000
1111 1110 0001
...
1111 1111 1110
-------------
0000~1111, 16条 OP
1111 1111 1111 0000
...
1111 1111 1111 1111
```

### 寻址分类学

实际上，就如同不同教材与体系对中断，异常，trap的分类不尽相同一样，对寻址做一个完美的分类也是不现实的。  
不过寻址总是可以分成**立即数**，**直接**与**间接寻址**的。  
- 立即数寻址，即立即数直接作为操作数，也不访存。
- 直接寻址，指给出的地址就是纯粹意义上的地址，不加任何修饰。
- 间接寻址，不直接给出操作数地址，而是给出存储操作数地址的主存地址/寄存器。

其中还有一类被分类为偏移寻址：
- **基址寻址**：
  相对于基址寄存器给出偏移量
- **变址寻址**： 
  相对于变址寄存器给出偏移量。只需把数组首地址放在IX，偏移量只需给下标辣！
- **相对寻址**：
  相对指的是相对于PC寻址。给出相对PC的偏移量。

可难道偏移寻址不是间接寻址？你可以在此处感受到分类的模糊。不必太过纠结。  

### 字长，编址，地址

>机器字长16位，按字节编址，CPU与主存连接地址线20根，数据线8位，采用16位定长指令。

地址线指示去哪个地址寻找目标，而数据线则真正地把该地址的数据拿出来。

- 机器字长表示一次能处理的数据位数，如ALU等，那么ALU宽度为16位。
- 地址线 * 编址宽度即主存大小。2^20B即2MB主存空间。地址位数也是PC寻址的范围。
- 要指示一个主存地址只需20根地址线，主存地址寄存器20位。
- 按字节编制，一个地址有1字节，那么数据线8位，主存数据寄存器也8位。
- 指令长16位，可以看出一条指令有2B，占用两个地址。指令与数据地位平等，在PC自增(+1)时实则+2。
- 指令16位，那么指令寄存器也有16位。

### RISC天下无敌

相比于CISC：
- RISC指令长度固定，指令格式种类少，寻址方式少。
- RISC只有load/store能够访存，其他指令都在寄存器中进行。
- 通用寄存器多。
- 指令使用频率较为平均，相差较少。
- 所有指令都采用流水线。大部分指令都能在1个周期内完成。
- 硬布线控制为主，尽量不像CISC搞微程序。
- 采用优化的编译程序。

## CPU 处理器

### 简易的总线知识

CPU与存储器的交互总是通过三条总线：地址总线，数据总线，控制总线。  
1. CPU将一个放在**地址总线**上的地址，一个放在**控制总线**上的控制信号发给存储器。
2. 存储器根据CPU指示的地址与控制信息，读入或写出数据到**数据总线**。


### 寄存器在CPU的分布

众所周知CPU由运算器，控制器构成。  

运算器内包含的寄存器有：
- **通用寄存器**
  一组对程序员可见的寄存器组，trapframe的保存对象。
- **累加寄存器** ACC 
  是通用寄存器的一种，包括x86在内的现代计算机可以用通用寄存器代替专用累加器。
- **暂存寄存器**
  通常与ALU协同工作。对程序员透明。
- **程序状态字寄存器** （Program Status Word Register）
  所谓程序状态，是一组保存程序控制信息的word。
  比如cond中使用的SF，CF，OF，ZF标志位就构成了其中的几位。
  该字中还包括如IF，是否允许终端位等系统工作信息。

控制器内的寄存器有：
- **程序计数器** Program Counter
  保存将要执行指令的地址。
  没想到吧，PC在控制器里。
- **指令寄存器** IR
  用于保存当前执行的指令，IR宽度与指令字宽相同。
- **存储器地址寄存器** MAR
  用于暂时存放CPU当前访存地址。宽度与主存地址线宽相同。
- **存储器数据寄存器** MDR
  暂存主存读出的一条指令/数据字。宽度与数据总线宽相同。

其中，通用寄存器，PC，PSW，ACC对**用户均可见**。  

这样的划分是非常合理的：
为了方便ALU运算，ACC与暂存R加入运算器是合理的。要执行更复杂的计算，将通用寄存器划分给运算器是显然的。为了执行条件判断，将PSW加入运算器是不言自明的。  

而要控制指令序列的流动，PC显然应属于控制器。要控制指令的执行，不管是取指还是访存都需要与主存的紧密配合，IR，MAR，MDR应运而生。

### 数据通路

所谓数据通路，即CPU内数据流通过的路径，途径逻辑元件(ALU)，存储元件(Memory)等。  

与主存的数据交互总是通过MAR与MDR的。如，取指需要根据PC设置MAR，再把指令取回到MDR。随后MDR再交给IR。  

从硬件的角度看，一个时钟周期能完成的操作是有限的。  
要注意区分流水周期：将指令执行过程划分成FDEMW，这是流水周期，可能内部包括几个时钟周期。

### 控制器

除了必要的寄存器，**指令译码器**(Instruction Decoder,ID
)也在控制器当中。  

此处控制器分为了两派，以CISC为代表的微程序控制器与以RISC为代表的硬布线控制器。

所谓**硬布线控制器**，就是使用复杂的电路布线组合生成控制信号。
而**微程序控制器**则是参考了软件程序设计思想来解决控制。

### 微程序控制器与微指令

一条指令对应一系列该指令要执行的操作，我们将这些操作抽象为一个**微程序**。所谓程序，就是一组可执行的指令序列，我们称在这个**微程序**里执行一系列**微指令**。这样每条指令就都对应一个微程序，对应一系列待执行的 微指令。  

每条指令对应的微程序在CPU设计完成后就确定下来，并存入**控制存储器**(Control Memory/Control Storage)。  

一条微指令可以进一步划分成控制字段，判别字段，下址字段。
- **控制字段**表示一系列要执行的微命令。对控制字段的编址可以直接编码，或者分成若干字段，段内互斥段间相容。
- **下址字段**表示下一条指令的地址。
  如果采用(PC+1)的方式，需要再次执行一次微地址翻译的过程，执行速度较慢。为了节省这样的开销可以引入额外字段。
  使用**下址字段法**/**断定法**，在微指令中设置一个专门的下址字段指示下一条微指令的地址。

### 典中典之异常中断

处理中断异常请求在硬件上是**控制器**的职能。当指令结束时，进行异常和中断判定，并进入处理程序。  

>此处不再赘述有关异常与中断的分类学问题。
>下文不区别异常与中断，一律用中断一词。

在OS软件的角度看，处理中断后需要保存上下文，并执行中断处理程序。而从体系结构的角度看，这个过程需要更多硬件的参与。

1. 硬件里总存在一个**寄存器**表示是否允许中断。如在PSW中，使用IF位表示当前程序是否允许中断。所谓开关中断，即令IF=0或1。
2. **异常处理程序**的职责是：保存上下文(trapframe)，事件处理，恢复上下文，开中断，返回。
3. **硬件**的职责是：关中断，保存断点(即PC，可软件化)，设置中断处理程序（判断中断源。

以RISC-V架构为例，trap的行为中，硬件不保存除了PC以外的任何寄存器，这意味着除了PC以外的必要的通用寄存器需要trapframe以软件形式保存并恢复。在多重跳转的情况下，我们可以认为即允许多重中断的条件下，trapframe中仍要保存PC的值，以免丢失。  

因此xv6的trapframe除了通用寄存器，也包含PC。所以说保存断点可以是硬件/软件实现的。

所以要完成一个中断(异常)，需要以下步骤：
1. **硬件**关中断
2. **硬件**保存PC值
3. **硬件**判断中断源，并设置中断处理。当涉及到interrupt通常指外部，如IO。下一跳进入中断处理程序。
4. **中断处理程序**保存上下文
5. **中断处理程序**处理中断事务
6. **中断处理程序**处理完毕，恢复上下文。
7. **中断处理程序**开中断
8. **中断处理程序**结束，返回。

有的时候硬件部分也叫做中断响应周期，或者中断隐指令。  

有一类中断称**非屏蔽中断**，表示事态紧急，即便处于关中断状态也要响应。与之对应的即可屏蔽中断。在允许**多重中断**的架构里，通过控制某中断源的**中断屏蔽字**，也可改变它被CPU处理的优先级。  

>值得注意的是，在更具体的使用情景，通常使用中断指代来自外部的异常，或者叫外中断，如IO操作。
>更具体的说，内部引起的异常exception，通常是不可屏蔽的，需要立即执行的。
>而中断interrupt，则两者都有。比如电源掉电属于不可屏蔽。
>**异常**总是在一条指令执行中发生，**中断**总是在指令执行后响应。

### 多重中断与屏蔽字

多重中断下，进入中断处理程序后需要**开中断**。  

我们所设置的**中断屏蔽字**，决定了处理的优先级。你应当这样理解中断的处理：  
任何一个中断发生，都要经过**先被响应**，**后被处理**的过程。
**响应优先级**所决定的是，假如有多个中断在同一时刻发生，我们应当先响应谁。
而**处理优先级**决定的是，一个**后抵达的中断**能否打断当前正在执行的中断。  

>举一个例子。假如在这同一时刻，发生了两个中断A与B。A的响应优先级高于B。由于A与B同时抵达了响应硬件，A将优先被硬件处理，保存断点，跳转至处理程序。
>
>当A正在执行他的处理程序，轮流到了B响应。B的响应硬件会先执行响应，即保存PC与计算跳转点。
>
>此时，假如B的处理优先级低于A，我们认为不允许B打断A的处理。所以此时这个响应将被挂起，等待A处理结束后轮到B处理。在这个期间硬件要保持B的挂起状态，因此不允许后续抵达的中断覆盖当前B的硬件状态，后续待响应的中断也要随着B一同等待，直到A完成了他的处理。
>
>而假如B的处理优先级高于A，那么我们认为允许B打断A的执行。因此，多重中断发生，B将进入中断处理，B此时保存了上下文，并在处理返回时恢复用于继续执行A的上下文环境。
在B转入中断处理时，B已结束了响应，中断响应硬件允许接受下一个响应了。下一个抵达的中断进入响应后，按照同样的处理优先级决定是否进行多重中断。


### 简单回顾指令流水

众所周知，五段流水被分成F，D，E，M，W五个功能段，段与段之间由流水线寄存器连接。
- **Instruction Fetch：**
  从当前PC取指令，分割指令段，确定valP，写入流水线寄存器。
- **Decode:**
  valA,valB,准备进一步的执行。
- **Execute:**
  执行ALU参与的必要的计算，生成valE。
- **Memory:**
  访存，生成valM。
- **WriteBack:**
  将结果写回到寄存器。
- **PC update:**
  更新程序计数器，在不同的实现中有差异。通常不独立成为功能段。

流水线其他内容详见CSAPP。

>要注意，功能段由流水线寄存器连接。
>假如I1在第一个时钟周期F。
>那么在第二个时钟周期，I1执行D，I2执行F。
>在第二个时钟周期刚开始时，D功能段从流水线寄存器读取必要数据执行。F功能段直接取指令。这是一个有过程的操作。
>这样就不必担心F的操作覆盖了流水线寄存器导致D错误，因为在寄存器覆盖前D已从流水线寄存器获得了所有必要的信息并开始了运行。

在**不引入转发**的前提下，相关性通常是F与D的**结构相关**，W与D的**数据相关**。
> 前D后F可以同时进行，却不允许后F提前覆盖流水线寄存器。


这里引入流水线的新技术：
- **多射流水线**，可以同时启动多条指令。由于指令在时间上并行，CPI小于1。
  多射还能分为静态与动态，静态称超长指令字，动态称超标量。
- **超流水线**，细化流水，提高主频，增加流水线功能段。但是由于并不并行，CPI仍为1。

## @TODO 新内容多核处理器

## 总线与IO系统-全是背诵

### 总线 Bus

**Bus**，如同其名字，即各种信息共同“乘坐”的一条传输线路。脱离总线结构意味着计算机的各个部件之间需要疯狂飞线各自为政，这显然不利于管理。  

- 为了避免冲突，同一时刻只能有一个设备向总线发送信息。
- Bus环主机绕一周，所有设备都能同时在总线上获得同样的信息。
  
总线按职能划分如下：
1. **数据总线**，双向传输数据，宽度同机械字长(存储字长)。
2. **地址总线**，单向传输地址，用以指示目标位置。
3. **控制总线**，双向传输控制信息。
  
### 总线事务

请求抵达总线到完成总线使用的一系列操作序列，称为**总线事务**，需要经历以下流程：
1. 总线请求，设备发出传输请求
2. 总线仲裁，当多个设备同时请求，选择一个。
3. 设备寻址，当设备获得了总线控制权，将设备地址与相关控制信息发送给总线。
4. 数据传输，主从设备进行数据交换，双向。
5. 总线释放，收回该设备对总线的控制权。

这个过程需要传送**地址**，并且在数据传输阶段只能传输**一个字长**。如果引入**总线突发传送方式**可以一次性传输连续的数据，只需要获得**首地址**。  

以及，总线地址/数据线的**复用**只能节省线路，不能提高数据传输率。很好理解，毕竟不能冲突。

### 其他Bus分类

总线也可以绑多个数据线在一起：
1. **并行总线**，把多个双向数据线绑在一起传输。
   但是由于线路过于密集相互干扰，线路过长时容易造成传输错误，只适合近距离通信。大多数系统总线通常是并行的。
2. **串行总线**，一条双向数据线/两条单向数据线
   没有并行那么娇贵，更适合远距离通信。大多数通信总线是串行的。

主从设备通过主线通信，需要遵循一些“协议”，完成一些操作。设备是按照时钟工作的，两者的协同也可以分为两种：
- **同步定时：** 信息交换由一个统一的时钟同步。
   但由于两设备强制同步，往往不能及时校验数据通信有效性。
- **异步定时：** 不统一定时，自己发自己的。但这就要引入新的控制方案。
   通过引入请求与确认信号握手来控制信息交换。

异步定时方案下，就有TCP握手内味儿了。请求信号与回答信号也可以撤销，异步定时方式又能进一步细分为：
- **不互锁：** 想撤销就撤销，快
- **半互锁：** 请求信号需要等待回答才能撤销。但是回答信号想撤就撤。
- **全互锁：** 双方互锁，必须双向等待。

### I/O接口

外部设备要和主机实现信息交换，显然我们需要一些接口协助这个过程。  
所谓I/O接口指逻辑意义上的接口，而不是物理意义上的“插口”。例如：xx适配器，xx控制器，等都可能是I/O接口。  

一个通用的I/O接口结构内部也有寄存器。
- 数据缓冲寄存器：暂存数据
- 状态寄存器: 接口与设备的状态信息
- 控制寄存器: CPU对外设的控制信息

既然是寄存器，显然CPU通过数据线访问它们。这些寄存器称**I/O端口**。
为了让CPU能够访问这些端口，我们也需要为它编址。有两种方案：
- **独立编址**： 为他们独立编址，译码简单，寻址更快。但是只支持简单的传输操作，并且需要独立的保护机制。
- **统一编址**： 将主存地址划分一部分给I/O端口。这意味着对I/O端口的访问可以复用对主存的操作，包括地址保护，分页等。但占用了部分主存空间。

### DMA

主机与外设与信息传输大概有三种方式。

- **程序查询方式**
  所谓程序查询就是让程序一直轮询(poll)访问I/O状态。
  这意味着CPU需要耗费时间不停访问。
- **中断访问方式**
  当I/O准备就绪，通过中断通知CPU进行处理。
  由于频繁中断的开销很大，并不适合**高速设备**。
- **DMA**
  在主存和设备的DMA接口直接拉条线传输数据。CPU只需参与少量控制。
  因为DMA每次传输单位是**块**，所以适合以块读写的外设。

DMA每次传输一整块，每块传送过程可以分成如下几个阶段：
- **预处理**
  CPU为DMA进行初始化。
- **数据传送**
  完全由DMA硬件控制，无需CPU的参与。
- **后处理**
  DMA结束后向CPU发起中断请求，完成数据校验等后处理工作。

DMA对主线的优先级要高于CPU，因为我们希望CPU能腾出更多时间处理其他事务，把数据传送交给DMA。

## 完结撒花

额外内容详见教材。