# CSAPP章节小结

## 第六章 存储器层次结构

- RAM和ROM的类型 用途 选择填空
- 计算磁盘容量,访问时间
- 主存读写过程


### 基础存储技术与用途

- 随机存取存储器RAM
  - 静态存储器SRAM ：Cache
  - 动态存储器DRAM : 主存
- 只读存储器ROM
  - 不可在线修改内容的ROM
  - 闪存Flash ROM : BIOS

### 磁盘(小题)

每个盘片两面,每面有磁道 每圈磁道划分为扇区

**计算磁盘容量**
>一个扇区512B 每磁道300扇区 每面有20000磁道 盘片有2面 有5个盘片
磁盘容量 = 512 * 300 *  20000 * 2 * 5 = 30.72GB

**计算访问时间**
1. 寻道时间 磁头移动到柱面所用时间 通常给定
2. 旋转延迟 移动到指定扇区所用时间 取转一圈时间的1/2
3. 数据传输时间 转过一个扇区所用时间

>给定旋转频率,寻道时间与扇区数
7200转/min 寻道时间9ms 每磁道400扇区
120转/s, 一转1/120 s
旋转延迟 $\frac{1}{2}*\frac{1}{120} * 10^3 =4.17ms$
传输时间 $\frac{1}{120}*\frac{1}{400}* 10^3 =0.02ms$
$T = 13.19ms$

### 主存读写

>(简答)当CPU执行movq A,%rax 会发生什么 P405
1,CPU总线接口(bus interface)在总线上发起读事务
2,CPU将A放到系统总线上,I/O桥将信号传到内存总线
3,主存感知到内存总线的信号,读入地址A,从DRAM取出数据,写到内存总线
4,I/O桥把内存总线翻译成系统总线信号,沿着系统总线传递
5,CPU感知到系统总线的数据,读入并复制到%rax

>CPU执行 movq %rax,A 同理
1,CPU发起写事务,将地址放到系统总线上
2,内存从内存总线读出地址,等待数据到达
3,CPU将%rax的数据复制到系统总线
4,主存从内存总线读数据字,存入地址A

### 局部性原理

>(简答)应用到计算机系统的哪些层次
硬件:
引入高速缓存存储器(cache),提高对主存的访问效率
操作系统:
使用主存作为虚拟地址空间最近被引用块的缓存
用主存来缓存磁盘文件系统中最近被使用的磁盘块
应用程序:
Web将最近被引用的文档放在本地磁盘

**在程序中利用局部性**
- 注意力集中在**内层循环**,大部分计算和访存都发生在这里
- 以**步长为1**读取数据 使得空间局部性最大
- 读入了一个数据对象就**尽可能多地使用**它 使时间局部性最大

### 金字塔

寄存器 -> L1,L2,L3高速缓存 -> 主存 ->本地磁盘 ->远程二级存储

### Cache-与第九章虚拟内存结合 必考

位于k层更快更小的存储设备作为k+1层更慢更大存储设备的缓存 即快的当慢的缓存
存储器被划分成块 数据以块为单位在两层之间来回复制

#### 相关概念
- 冷不命中:缓存为空 可以经过暖身后稳定下来
- 冲突不命中:对象被不停地映射到同一个缓存块 抖动
- 容量不命中:缓存不够大 放不下

- 放置策略:决定块放在Cache的哪个位置
- 替换策略:决定新块替换哪个旧块
- 写回策略 决定Cache在写时如何改变主存

只要发生了不命中就要进行放置策略
对于层次**较高**的缓存(靠近CPU),是用硬件实现的。
最灵活的放置策略是随机放置，但实现起来很昂贵,定位代价很高
因此**硬件缓存**通常使用更严格的放置策略(不随机放)
如取模映射,这种**限制性的放置策略**造成了**冲突不命中**

#### 高速缓存存储器 L1,L2,L3

高速缓存被**分成组**,每组**若干行**,每行有1个有效位(valid bit),若干标记位和一个2^b大小的块
假设地址有m位, 可以形成M = 2^m个地址
S(set) = 2^s ,组数
E(cache line),每组有多少个高速缓存行
B(Byte) = 2^b,数据块的大小
t(tag bit) = m-b-s ,标记位,来唯一标识一个块

对于一个m位的地址:<t位标记位>+<s为组索引>+<b位块偏移>可确定哪组,哪行,块内的哪个位置
>之所以把索引位放中间是因为对于连续的地址高位很容易重复,这会导致很多相邻的块被映射到同一个组

则高速缓存的**整个大小**(总块大小,不算标记位和有效位) $C = S * E * B$

#### 直接映射高速缓存

<t位标记位>+<s为组索引>+<b位块偏移>

**每个组只有一行**的高速缓存,即一行就是一组,E=1
行匹配非常简单,只需与唯一一行的标记位比较即可
替换策略也非常简单，直接替换唯一的行

会经常发生**冲突不命中**,即抖动

#### 组相联高速缓存

<t位标记位>+<s为组索引>+<b位块偏移>

每组多于一行 E>1
在确定组后需要**组内遍历每一行**寻找标记位匹配的行
替换策略:LFU，LRU等 了解即可

#### 全相联高速缓存

<t位标记位> + <b位块偏移>

一个大组,包含所有的行
不再需要组选择因为就一个组,默认选择组0

行匹配依然需要遍历所有行 非常昂贵
所以全相联高速缓存只**适合做小的高速缓存**
如虚拟内存的快表(TLB)

#### 关于写

- 写命中,缓存已写入,如何处理低一层
  - 直写:缓存直接写回到低一层,每次写会引起总线流量
  - 写回:推迟更新,当写命中的块要被替换掉的时候再写到低一层,减少了总线流量但增加了复杂性,需要维护额外的修改位
- 写不命中,缓存里没有
  - 写分配(指分配到高速缓存):加载底层这个块到缓存里 缺点是每次不命中都要从低层传送块到高速缓存 但能利用空间局部性(最近被写过)
  - 非写分配:避开高速缓存,直接把这个字写入低一层,不直接拿入高速缓存

通常而言有以下组合:
- 直写+非写分配,直接写低层并不主动载入缓存
- **写回+写分配**,命中时暂缓对低层的更新,不命中时被写块主动加入缓存

#### 性能影响

- **高速缓存大小**:大高速缓存可以提高**命中率** 但增加了**命中时间**(遍历行)
- **块大小**:大块能更好地利用**空间局部性** 但对于给定大小的高速缓存意味着**更少的行** 损害了**时间局部性** 块越大**传送时间越长**，不命中处罚越严重
- **相联度**:高相联度降低了**冲突不命中** 但造成**较高的成本**(相联很贵) **命中时间**(更多的行)与**不命中处罚**(牺牲行的复杂度增加)
- 写策略:一般而言,越往**下层**越可能使用**写回**而不是直写，因为越往下传送时间就越长，要尽可能减少传送数量使用写回 

### 面向cache的优化-结合第五章优化

调整变量顺序:重新排列(空间局部性)
>见上一章A[i][j][k]

分块矩阵(时间局部性):非重点
>略


### 给参数算地址

块大小在实际中认为64字节
- L1: 32KB,8-way
- L2: 256KB,8-way
- L3: 8MB,16-way
- 块大小：64B
>以Core i7 L1数据缓存为例
32kB八路组相连,一块64字节
C = 32kB =32768 B
B = 64B,b=6
E = 8,e=3
一共多少块:$32kB/64B =0.5*2^{10}=512$
一块一行,有512个缓存行,一组8行
组数 $512/8=64$组
即S=64,s=6

给定地址范围:47位 得到
{35位标记}{6位组索引}{6位块偏移}
>0x 00 00 7f 72 62 a1 e0 10 解析这个地址
末尾12位:0x010,0000 0001 0000
块偏移:010000,0x10,
组索引000000,0x0,第0组
标记位0x00007f7262a1e

### 分析不命中

例6.18~6.20 P443

```
struct position{
    int x;
    int y;
}
struct position grid[16][16];
int total_x=0,total_y=0;
int i,j;
```
假设sizeof(int) = 4 高速缓存开始为空,i,j,total均在寄存器
块大小16B 直接映射Cache大小1024B

- **例6.18**
```
for(i=0;i<16;i++){
    for(j=0;j<16;j++){
        total_x +=grid[i][j].x;
    }
}
for(i=0;i<16;i++){
    for(j=0;j<16;j++){
        total_y +=grid[i][j].y;
    }
}
```
1024/16 = 64组,每组1行
Cache容量能容纳半个数组
```
#Cache:
组号  块
0   grid[0][0] grid[0][1]
1   grid[0][2] grid[0][3]
2   grid[0][4] grid[0][5]
3   grid[0][6] grid[0][7]
...
63  ...
```
一共访存:16 * 16 * 2=512次
一次不命中,一次命中,一半一半 不命中256次
不命中率50%

- **例6.19**
```
for(i=0;i<16;i++){
    for(j=0;j<16;j++){
        total_x +=grid[j][i].x;
        total_y +=grid[j][i].y;
    }
}
```
i j的对调造成了空间局部性的下降 C语言按行处理,分块也按行,Cache也按行分块
```
#Cache:
组号  块
0   grid[0][0] grid[0][1]
1   grid[1][0] grid[1][1]
2   grid[2][0] grid[2][1]
3   grid[3][0] grid[3][1]
...
63  ...
```
这会导致x每次都不会命中.但y的读取紧跟在x后所以y必命中
总访存:2 * 16 * 16 = 512
不命中:256
不命中率:50%
若将数组扩大一倍,使其能容纳下整个数组:
```
0   grid[0][0] grid[0][1]
1   grid[1][0] grid[1][1]
2   grid[2][0] grid[2][1]
3   grid[3][0] grid[3][1]
...
?     grid[0][2] grid[0][3]
?+1   grid[1][2] grid[1][3]
?+2   grid[2][2] grid[2][3]
?+3   grid[3][2] grid[3][3]
...
```

也就是说x有一半命中 128
不命中率:128/512 = 25%

- 例6.20

```
for(i=0;i<16;i++){
    for(j=0;j<16;j++){
        total_x +=grid[i][j].x;
        total_y +=grid[i][j].y;
    }
}
```
把两个对grid的访存放在同一循环里,比6.18更进一步利用了空间局部性
同理y必命中,不命中的都是x
x是冷不命中,128次不命中
不命中率128/512 = 25%
即便扩大Cache容量一倍,x依然会不命中128次,不命中率不变