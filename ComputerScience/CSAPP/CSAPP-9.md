# CSAPP章节小结

## 第九章 虚拟内存

- 虚拟地址空间映射与虚拟存储器概念
- 系统构成与实现
- 动态存储器分配与管理技术

### 物理与虚拟寻址

CPU访问内存的最自然方式是使用物理寻址
早期的PC使用物理寻址,而现代处理器使用虚拟寻址
CPU通过虚拟地址来访问主存
CPU芯片上得到内存管理单元MMU(memory management unit)负责地址翻译将虚拟地址转换为物理地址

### 虚拟内存

**虚拟内存**被组织为一个存放在**磁盘**上连续字节大小的单元组成的数组
每字节都有一个唯一的**虚拟地址**作为**索引**
与其他层次的缓存一样磁盘上的数据也被划分成块,在主存与磁盘之间传输
虚拟内存被分割成固定大小的块,称**虚拟页**(virtual page)
在物理内存则称为**物理页**(physical page),大小相同
物理页也称作**页帧**(page frame)

虚拟页面的集合被划分为三种
- **未分配的** VM系统未分配/创建的页 没有任何数据 也不占用磁盘空间
- **缓存的** 这些虚拟页在物理内存中已缓存
- **未缓存的** 未缓存在物理内存但实际上已分配的页

**SRAM**缓存指L1,L2,L3高速缓存
而我们使用**DRAM**来表示虚拟内存系统的缓存,他在主存中缓存虚拟页,把主存当做磁盘上划分出的虚拟页的缓存

#### 页表

VM系统必须能够判定一个虚拟页是否缓存在DRAM中,
如果是,还必须确定这一虚拟页放在哪个物理页中.
如果不命中,系统要判断该虚拟页在磁盘中的位置,并在物理内存中选择一个牺牲页,并用虚拟页替换掉
这些功能由软硬件联合提供,包括操作系统,MMU中的地址翻译硬件,与一个存放在物理内存中的**页表**(page table)

页表将虚拟页映射到物理页,**地址翻译硬件**转换地址时会**读取页表**
**操作系统**负责**维护页表**的内容并在磁盘与DRAM之间**传送页**

每一个虚拟页都对应了一个**页表条目**(Page Table Entry)(即页表项)
PTE由一位有效位和n位地址字段组成
- 设置了有效位 表示该页已缓存在DRAM中,地址字段表示其物理页的起始位置
- 没有设置有效位 如果地址未空,表示该虚拟页未分配 不然表示虚拟页在磁盘上的起始位置

DRAM缓存不命中成为缺页(page fault),这会触发一个缺页异常,调用内核的缺页异常处理程序,该程序选择一个牺牲页

#### 局部性

由于局部性原理,这种页面调度工作的相当好
局部性原理保证了在任意时刻,程序趋向于在一个较小的活动页面集合上工作
称之为工作集(working set)或者常驻集合(resident set)
在缓存了这些集合中的页后,对这个工作集的引用都会导致命中
只要程序有好的时间局部性,虚拟内存工作系统就能工作得相当好

然而如果时间局部性不够好,工作集的大小变得很大超出了物理内存的大小
则会产生抖动,页面不断地换进换出

#### 如何管理内存

虚拟内存大大简化了内存管理,并提供了自然地保护内存的方法

- **简化链接** 操作系统为每一个进程都提供了一个独立的页表,因而也就是一个独立的虚拟地址空间,这允许每个进程的映像都使用相同的基本格式,例如64位地址空间而言代码段总是从虚拟地址0x40000开始.格式的一致性极大地简化了链接器的设计与实现
- **简化加载** 把目标文件.text与.data节加载到新进程的过程中,加载器(loader)只需为代码与数据段分配虚拟页,标记为未被缓存的,将页表条目指向目标文件中的恰当位置,虚拟内存系统即可自动地按需调入数据页
- **简化共享** 对于进程私有代码,操作系统会创建页表,把虚拟页映射到不同的物理页 在一些情况中,例如每个进程调用相同的内核代码,将不同进程中虚拟页面映射到相同的物理页,从而共享这段代码的一个副本
- **简化内存分配** 当程序要求额外的堆空间时(如malloc),操作系统分配**连续的虚拟内存页面**,而可以把他们映射到**物理内存**中的**任意位置**

#### 内存保护

如果对PTE添加一些许可位,如**SUP,READ,WRTIE**来标识这个页的是否需要内核态与对读写的控制
当指令违反了这些许可条件,CPU触发一个故障保护,控制传递给异常处理程序
Linux shell一般称这种异常为段错误(segmentation fault)

#### 地址翻译

CPU中的**页表基址寄存器PTBR**(Page Table Base Register)指向页表
一个n位虚拟地址包含两部分:
- p位**虚拟页面偏移**VPO(Virtual Page Offset):代表所指页的页内偏移
- n-p位**虚拟页号**VPN(Virtual page Number):虚拟页号指向页表中的某一项

MMU根据虚拟页号VPN来确定页表中的某一页表条目PTE
对于已缓存的虚拟页,其页表项中给出了**物理页号**PPN(Physical Page Number)
现在将**物理页号**PPN与**页内偏移**VPO拼在一起就可以得到**物理地址**

页面命中的过程如下
- 处理器把虚拟地址传送给MMU
- MMU得到虚拟页号,向高速缓存/主存请求读页表中的PTE
- 高速缓存/主存返回所请求的PTE
- MMU把PTE中得到的PPN与虚拟页号中的VPO拼在一起,构造出物理地址,传送给高速缓存/主存
- 高速缓存/主存返回所请求的数据字给处理器

页面命中完全由硬件处理,而对于不命中则需要操作系统内核协作完成
- 处理器把虚拟地址传送给MMU
- MMU得到虚拟页号,向高速缓存/主存请求读页表中的PTE
- 高速缓存/主存返回所请求的PTE
- PTE中有效位是0,触发缺页异常,控制传递给缺页异常处理程序
- 缺页处理程序确定出物理内存的牺牲页,如果这个页面已被修改则换出到磁盘
- 调入新的页面,更新页表中的PTE
- 缺页处理程序返回到原来的进程,再次执行导致缺页的指令.CPU将虚拟地址重新发送给MMU.因为已把对应页换入内存,这会导致命中,接下来进入页面命中的流程

#### 快表TLB

每次产生虚拟地址的过程MMU都要查PTE
在MMU中加入一个关于PTE的小缓存快表TLB(Translation Lookaside Buffer)来试图消除这样的开销
PTE保存着由单个PTE组成的块

当TLB命中时,所有的地址翻译都在MMU中执行,非常快
- CPU传递虚拟地址
-  MMU得到虚拟页号,查TLB得到所求PTE
-  TLB返回请求的PTE
-  MMU翻译出物理地址,传递给高速缓存/主存
-  高速缓存/主存返回请求的数据字

TLB不命中时,MMU需要从L1中取出所求PTE,并放入TLB.这可能会牺牲已有的PTE块

TLB的**索引与标记字段**来自于虚拟地址的**虚页号字段**
<标记位><索引位><VPO>

#### 多级页表

假设地址空间32位,页面大小4KB,PTE大小4B
$\frac{2^{32}}{4*2^{10}}*4 = 4*2^{20}=4MB$
这意味着即便只引用一小部分虚拟地址空间,也需要4MB的页表常驻内存
如果地址空间64位,则需要$2^{54}B$的页表,我们无法承受这样的代价

压缩页表的常用方法是使用层级结构的页表
以二级页表为例
一级页表中的每个PTE映射到一个二级页表
二级页表中的PTE才映射到物理内存
基于上述假设不变,
考虑一个大小为4KB的一级页表,
一级页表有$4KB/4B=1024$个PTE
每个一级PTE指向一个二级页表
每个二级页表大小4KB,也容纳1024个PTE,负责映射到物理内存
此时,一级页表与每个二级页表的页表


大小与一个页面大小一样都是4KB
这从两个方面减少了内存要求
- 如果一级页表的PTE为空,则其二级页表根本不会存在,从而节约了空间
- 只有一级页表常驻主存,而只有常用的二级页表才会缓存在主存

#### 端到端地址翻译

P573,P577
(2022)P577原图

Intel I7默认是4级页表
如:32位虚拟页号, 则每级页表32/4=9位

#### Linux虚拟内存系统

Linux缺页异常处理:
- 该虚拟地址是否合法?若不合法,触发段错误(segment fault) 终止该进程
- 该内存访问是否合法?若不合法,触发保护异常,终止该进程
- 都合法,认为是缺页引起,进行缺页处理

### 共享与私有

不同进程的虚拟内存映射到物理内存的同一区域
私有对象采用**写时复制**
- 两个进程的私有对象映射到了同一个物理副本,标记该区域为**私有的写时复制**
- 在没有进程试图写该区域,则继续共享同一个副本
- 当有进程试图写该区域,则触发故障保护
- 在物理内存中创建所写页面的新副本,并更新页表指向这个新的副本页
- 恢复这个新副本页的可写权限,这样这个新页面上的写操作就可以正常执行

### 内存分配

2021: 简述内存释放并合并空闲块的过程
写出内存块释放与空闲块合并的C语言函数 加注释
可以使用题目给出的宏与宏函数

#### 动态内存分配

动态内存分配器(dynamic memory allocator)维护一个进程的虚拟内存区域:堆(heap)
内核维护一个变量brk(break),指向堆的顶部

分配器视堆位一组不同大小的块(block)的集合 每个块是一个连续的虚拟内存片(chunk) 要么是**已分配的**,要么是**空闲的**

已分配的块显示地保留给应用程序使用,**空闲块可以用来分配**
已分配的块可以被释放,这种释放可以使应用程序显示执行,也可以是内存分配器隐式执行的

有两种风格:
- **显式分配器**(explicit allocator) 要求应用显式地释放已分配的块 如C标准库提供malloc显示分配器 用free来释放
- **隐式分配器**(implicit allocator) 要求分配器检测已分配块何时不再被使用并释放 也叫**垃圾收集器**(garbage collector) 自动释放已分配的块的过程叫**垃圾收集**(garbage collection) 如Java依赖垃圾收集来释放已分配的块

#### malloc与free

```
void *malloc(size_t size);
```
malloc返回的指针指向大小至少为size字节的内存块
块可能为其内部的数据对象类型做对齐,64位下该地址通常是16的倍数
当malloc遇到问题:如要求的内存块过大 就返回NULL

```
void *sbrk(intprt_t incr);
```
sbrk通过将内核的brk指针增加incr来扩展或收缩堆
成功返回brk的旧值 失败返回-1

```
void free(void *ptr);
```
ptr必须指向malloc,calloc,realloc获得的已分配块的起始位置
不然free的行为将是未定义的 且什么都不返回,也不会告诉应用发生了错误

#### 分配器的要求与目标

限制要求:
- 只使用堆
- 对齐块
- 不破坏已分配的块
- 立即响应请求
- 任意的分配与释放序列

性能目标:
- 最大化吞吐量(单位时间内完成的请求数)
- 最大化内存利用率

在限制要求下,这两个性能目标通常是相互冲突的
- 若希望吞吐率最大化,则使请求平均时间最小化
- 峰值利用率 $U_k=\frac{max_{i<=k}P_i}{H_k},P:payload;H:Heapsize$ 描述了前k+1个请求中利用率的最大值

若想利用率最大化,就要尽量减少碎片,多合并空闲块,这意味着更复杂的分配策略,增大了分配时间
我们可以以堆利用率为代价写出吞吐率最大化的分配器:使用最简单的分配策略,最小化分配时间

#### 碎片

- 内部碎片:一个已分配的块比有效载荷大
- 外部碎片:没有一个单独的空闲块足够大承载载荷

**外部碎片**的量化要困难得多,且不可能预测,分配器通常采用启发式策略来**维持少量的大空闲块**,而不是维持大量的小空闲块

#### 隐式空闲链表

任何实际的分配器需要一些数据结构来区分**块的边界,已分配或空闲**
大多数分配器将这些信息嵌入块本身

```
//一个简单的堆块格式
29bit  :  头部,给出块大小
3bit   :  其他信息,如区分已分配/空闲
payload:  载荷
(可选填充)
```
对这个结构做如下考虑:
双字(8B)对齐,则块的大小是8的倍数,块大小字段低3位一定是0
所以抽掉3bit用于状态其他信息: 0 0 a 用a指明已分配/空闲

考虑一个已分配的块,总大小为24B(0x18)
```
//其头部:
0x00000018 | 0x1 = 0x00000019
    1 1000
+      001
=   1 1001
0x18+0x1=0x19
```

我们可以将堆组织为一个连续的已分配块和空闲块的序列 用隐式链表串联
空闲块通过头部的大小字段隐含地连接着
分配器可以遍历堆中所有的块从而间接遍历空闲块的集合

我们还需要一个特殊的结束块:大小为0,标记位已分配的**终止头部**(terminating header)

- 优点是简单
- 缺点是任何操作的开销都要求对链表的搜索 搜索时间与块的总数成线性关系

#### 放置策略

找到一个足够大的空闲块放置请求

**首次适配**(first fit):选择第一个合适的空闲块
- 倾向于把较大的空闲块保留在链表的后面
- 缺点是靠近链表起始处留下小空闲块的碎片 增加了对较大块的搜索时间

**下一次适配**(next fit):在上一次查询结束的位置开始首次适配
- 好处是跳过了首次适配前面可能造成的碎片 更快
- 但内存利用率比首次适配低很多

**最佳适配**(best fit):检查所有空闲块,选能满足请求的最小块
- 内存利用率最高
- 但这要求对堆进行彻底的搜索

#### 分割空闲块

当找到一个匹配的空闲块 要做另一个策略决定:分配该块多少
- 分配整个空闲块:造成内部碎片
- 分割这个空闲块,分配一部分:产生外部碎片

#### 额外堆内存

如果找不到合适的空闲块:
一个选择是合并物理上相邻的空闲块来创建更大的空闲块
如果还是不够大,
则调用sbrk函数,向内核申请额外的堆内存 分配器把额外的内存转化为一个更大的空闲块,插入空闲链表

#### 合并空闲块

当一个已分配块被释放,其他空闲块与这个新释放的空闲块相邻,则引起一种现象:**假碎片**(fault fragmentation),许多可用的空闲块被切割成小的,无法使用的空闲块

因此任何实际的分配器都必须**合并**(coalescing)相邻的空闲块
何时执行合并又是一个重要的策略决定
- **立即合并**:块被释放时就合并所有的相邻块
- **推迟合并**:等到某个稍晚的时候再合并(如直到某个分配请求失败再合并)

立即合并很简单明了,可以在常数时间内完成
但对于某些请求模式会产生一种形式的抖动,块反复地合并又马上被分割
**快速的分配器**通常会选择某种形式的**推迟合并**

#### 带边界标记的合并

合并当前块的**下一个块**很简单,因为当前块的头部指向下一个块的头部,可以检查指针判断下一个块是否空闲
**合并前面的块**则需要搜索整个链表,记住前面块的位置 这意味着每次free需要的时间与堆的大小成线性关系

一种聪明而通用的技术:**边界标记**(boundary tag)
在每个块的结尾添加一个**头部的副本**:**脚部**(footer)
如果每个块都有这样一个脚部
则检查当前块开始位置的前一个字的位置,就得到了上一个块的脚部 从而判断上一个块的分配情况

不过这也带来了显著的内存开销

#### 显式空闲链表

对于隐式空闲链表,块分配与堆块的总数呈线性关系
对于通用的分配器,隐式空闲链表并不适合

更好的方法是将空闲块组织为某种形式的**显式数据结构**
堆可以组织为**双向空闲链表** 每个空闲块中都包含pred于succ

首次适配的分配时间从**块总数**的线性时间减少到**空闲块总数**的线性时间

### 分配器实现

第一个字是双字边界对齐,不使用的**填充字**
后面紧跟:**序言块**:8字节的已分配块,只有header与footer,初始化时创建,永不释放
以**结尾块**:大小为0的已分配块 结尾


#### 内存模型系统

```
/*private global variables*/
static char* mem_heap;      //指向堆的起始地址
static char* mem_brk;       //指向堆的最后一字节+1
static char* mem_max_addr;  //堆的最大合法地址+1

/*Initialize*/
void mem_init(void){
    mem_heap = (char*)malloc(MAX_HEAP);
    mem_brk = (char*)mem_heap;                  //初始化为堆起始地址
    mam_max_addr = (char*)(men_heap+MAX_HEAP);  //指向最大合法地址+1
}

/*sbrk implement*/
void* mem_sbrk(int incr){       //一个简化版sbrk函数
    char *old_brk=mem_brk;
    //报错
    if(incr<0||(mem_brk+incr)>mem_max_addr){
        errono = ENOMEM;
        fprintf(stderr,"ERROR:mem-sbrk failed:ran out of memory.\n");
        return (void*)-1;
    }
    mem_brk+=incr;
    return (void*)old_brk;
}
```

#### 常用函数与宏

```
#define WSIZE 4             //字大小4B
#define DSIZE 8             //双字double word 8B
#define CHUNKSIZE (1<<12)   //扩展堆时的默认大小:2^12=4MB

#define MAX(x,y)

/*将块大小字段与已分配位拼接 用于header或footer*/
#define PACK(size,alloc) ((size)|(alloc))

/* 
 * 读取/写入p所指的字
 * p典型地是一个(void*)指针
 * 强转为unsigned int* 并读取p所指的字
 */

#define GET(p) (*(unsigned int *)(p))
#define PUT(p,val) (*(unsigned int*)(p) = (val))

/*
 * 读p所指的header或footer下SIZE字段与ALLOC位
 * 在当前模型下header与footer刚好占1字
 */
#define GET_SIZE(p) (GET(p) & ~0x7)
#define GET_ALLOC(p) (GET(p) & 0x1)

/*
 * 给定block ptr bp,计算它header/footer的地址
 * bp指向有效载荷部分
 */
#define HDRP(bp) (char*)bp - WSIZE
#define FTRP(bp) (char*)bp + GET_SIZE(HDRP(bp)) -DSIZE

/*
 * 前一个/后一个块的地址
 */
#define NEXT_BLKP(bp) ((char*)(bp) + GET_SIZE(HDRP(bp)))
#define PREV_BLKP(bp) ((char*)(bp) - GET_SIZE(HDRP(bp) - WSIZE))
```

#### 初始化堆与扩展堆

```
int mm_init(void){
    if((heal_listp = mem_sbrk(4*WSIZE)) == (void*)-1)
        return -1;
    PUT(heap_listp,0);                          //填充块
    PUT(heap_listp + 1 * WISZE,PACK(DSIZE,1));  //序言块header
    PUT(heap_listp + 2 * WSIZE,PACK(DSIZE,1));  //序言块footer
    PUT(heap_listp + 3 * WSIZE,PACK(0,1));      //结尾块
    heap_listp += 2*WSIZE;

    //分配一个块
    if(extend_heap(CHUNKSIZE/WSIZE) == NULL){
        return -1;
    }
    return 0;
}
```
```
static void* extend_heap(size_t words){
    char *bp;
    size_t size;
    size = (word%2) ? (words+1)*WSIZE:words*WSIZE; //对齐
    if((long)(bp=mem_sbrk(size))==-1)
        return NULL;

    PUT(HDRP(bp),PACK(size,0));
    PUT(FTRP(bp),PACK(size,0));
    PUT(HDRP(NEXT_BLKP(bp)),PACK(0,1));

    //如果前一个块空闲则合并
    return coalesce(bp);
}
```

#### 释放与合并块
```
void mm_free(void *bp){
    size_t size = GETSIZE(HDRP(bp));    //计算当前块大小
    PUI(HDRP(bp),PACK(size,0));         //头部归0
    PUT(FTRP(bp),PACK(size,0));         //尾部归0
    coalesce(bp);
}
```

```
static void *coalesce(void *bp){
    size_t prev_alloc = GET_ALLOC(FTRP(PREV_BLKP(bp))); //前
    size_t next_alloc = GET_ALLOC(HDRP(NEXT_BLKP(bp))); //后
    size_t size = GET_SIZE(HDRP(bp));                   //当前块大小

    //前后不空
    if(prev_alloc && next_alloc) 
        return bp;

    //前不空后空
    if(prev_alloc && !next_alloc){
        size += GETSIZE(HDRP(PREV_BLKP(bp)));   //修改大小
        PUT(HDRP(bp),PACK(size,0));             //修改头,释放并合并
        PUT(FTRP(bp),PACK(size,0));             //重写尾
    }

    //前空后不空
    if(!prev_alloc && next_alloc){
        size += GETSIZE(HDRP(PREV_BLKP(bp)));   //修改大小
        PUT(FTRP(bp),PACK(size,0));             //写尾
        PUT(HDRP(PREV_BLKP(bp)),PACK(size,0));  //写头
        bp = PREV_BLKP(bp);                     //bp前移
    }

    //前后都空
    if(!prev_alloc && !next_alloc){
        size += GETSIZE(HDRP(PREV_BLKP(bp))) + GET_SIZE(FTRP(NEXT_BLKP(bp)));   //HDRP与FTRP等价 此处为习惯写法
        PUT(HDRP(PREV_BLKP(bp)),PACK(size,0));                                  //写前头
        PUT(FTRP(NEXT_BLKP(bp)),PACK(size,0));                                  //写后尾
        bp = PREV_BLKP(bp);                                                     //bp前移
    }
    return bp;
}
```
合并:共4个情况
- 前空后空
- 前空后不空
- 前不空后空
- 前后不空

#### 分配块

```
//向内存请求size大小的块
void *mm_malloc(size_t size){
    size_t asize;       //调整请求大小
    size_t extendsize;  //拓展堆
    char *bp;

    if(size==0) return NULL;

    //最小块大小为双字16B
    if(size < DSIZE)        //小于双字
        asize = 2*DSIZE;    //调整为双字大小 并额外加一双字用于header与footer
    else                    //加入开销字节,向上舍入到最接近8的整数倍
        asize = DSIZE * ((size + DSIZE + DSIZE-1)/DSIZE); //wtf

    if((bp=find_fit(asize)) !=NULL){
        place(bp,asize);
        return bp;
    }

    //没找到,拓展
    extendsize = MAX(asize,CHUNKSIZE);
    if((bp = extend_heap(extendsize/WSIZE))==NULL)  //拓展失败
        return NULL;
    place(bp,asize);
    return bp;
}
```

### 垃圾收集

垃圾收集器是一种动态内存分配器 自动释放程序不再需要的块

垃圾收集器将内存视为一张**有向可达图**
图的结点被分为一组**根节点**与一组**堆结点**
**堆结点**对应了堆中的一个**已分配块**
有向边 $p→q$ 意味着块p中的某个位置指向块q中的某个位置
**根节点**对应了一种**不在堆中**的位置,包含指向堆的指针.这些位置可以使寄存器,栈里的变量

当存在从根出发到达p的有向路径,称p结点可达
在任何时刻,不可达结点对应垃圾,不能被应用再次使用

如Java的垃圾收集器堆如何应用和创建指针有很严格的控制,能够维护可达图的精准表示,也能回收所有垃圾
而如C,C++的收集器通常不能维持可达图的精准表示,这样的收集器也叫**保守的垃圾收集器**
即一些不可达结点会被错误的标记位可达