# Universal Approximation Theorem

George Cybenko于1989年发表的论文 *Approximation by superpositions of a sigmoidal function* 第一次严谨证明了:

>使用单隐藏层、有限个神经元，激活函数取 sigmoid，前馈网络就能逼近任意连续函数。

1990s，该定理得到推广，证明了只要激活函数是“非线性且可测的”，就满足类似的通用逼近性质。

其思想来源于数学上的逼近论。如使用多项式逼近任意精度的连续函数，或者使用傅里叶级数展开逼近周期函数。将其思想推广到神经网络，即得到**通用近似定理**。神经元的输出函数可以作为“基函数”，通过线性组合就能拼出任意连续函数。

---

UAT只是一个存在性定理，即说明了有解，却不能说明如何找到这个解。同时，逼近不等于泛化，仍需要处理过拟合问题。

在数学上，我们可以视其为一个新的函数逼近工具，一个万能的近似基，一个**逼近器**(Approximator)。多项式基和傅里叶基都是固定的，而神经网络的基却是通过训练自动学习的。

---

当你建立起了若干layer搭建出一个神经网络，你实际上是在期望这些东西能复合一个足够复杂的函数，使其逼近一个尚不可知的预测函数。